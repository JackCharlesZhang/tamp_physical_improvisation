{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Distance Heuristic V4 Training - Contrastive State-Node Learning\n",
        "\n",
        "This notebook trains V4 which conditions on goal NODES rather than goal STATES.\n",
        "\n",
        "## Key Improvements over V3\n",
        "1. Policy conditions on goal nodes (not states) - avoids invalid state pairs\n",
        "2. Dual encoder architecture: s_encoder (state→embedding) + g_encoder (node→embedding)\n",
        "3. Simplified contrastive loss with normalized embeddings\n",
        "4. No L2 regularization or dual formulation needed\n",
        "\n",
        "## Goals\n",
        "1. Collect training data (state-node pairs from planning graph)\n",
        "2. Train distance heuristic using contrastive state-node learning\n",
        "3. Evaluate learned distances vs true distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch version: 2.9.0+cu128\n",
            "CUDA available: False\n",
            "Using device: cpu\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "# Add src to path if needed\n",
        "sys.path.insert(0, str(Path.cwd().parent / \"src\"))\n",
        "\n",
        "from tamp_improv.benchmarks.gridworld_fixed import GridworldFixedTAMPSystem\n",
        "from tamp_improv.approaches.improvisational.base import ImprovisationalTAMPApproach\n",
        "from tamp_improv.approaches.improvisational.policies.multi_rl import MultiRLPolicy\n",
        "from tamp_improv.approaches.improvisational.policies.rl import RLConfig\n",
        "from tamp_improv.approaches.improvisational.collection import collect_total_shortcuts, collect_total_planning_graph\n",
        "from tamp_improv.approaches.improvisational.distance_heuristic_v4 import (\n",
        "    DistanceHeuristicV4,\n",
        "    DistanceHeuristicV4Config,\n",
        ")\n",
        "from tamp_improv.approaches.improvisational.graph_training import compute_graph_distances\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Create Gridworld Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Action space is not Box, using original action space.\n",
            "✓ Created GridworldTAMPSystem\n",
            "  System name: TAMPSystem\n",
            "  Action space: Discrete(5)\n",
            "  Observation space: Graph(Box(0.0, 10.0, (2,), float32), None)\n"
          ]
        }
      ],
      "source": [
        "# Create tiny gridworld\n",
        "system = GridworldFixedTAMPSystem.create_default(\n",
        "    num_cells=2,\n",
        "    num_states_per_cell=5,\n",
        "    num_teleporters=0,\n",
        "    seed=42,\n",
        "    max_episode_steps=200,\n",
        ")\n",
        "\n",
        "print(f\"✓ Created GridworldTAMPSystem\")\n",
        "print(f\"  System name: {system.name}\")\n",
        "print(f\"  Action space: {system.env.action_space}\")\n",
        "print(f\"  Observation space: {system.env.observation_space}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Collect Training Data\n",
        "\n",
        "This builds the planning graph and collects state pairs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Created approach\n"
          ]
        }
      ],
      "source": [
        "# Create approach for collection\n",
        "rl_config = RLConfig(device=device)\n",
        "policy = MultiRLPolicy(seed=42, config=rl_config)\n",
        "approach = ImprovisationalTAMPApproach(system, policy, seed=42)\n",
        "approach.training_mode = True\n",
        "\n",
        "print(\"✓ Created approach\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Collecting training data...\n",
            "\n",
            "================================================================================\n",
            "Collecting total planning graph from 100 episodes\n",
            "================================================================================\n",
            "Building total planning graph from 100 episodes...\n",
            "\n",
            "=== Episode 1/100 ===\n",
            "Planning graph with 4 nodes and 4 edges\n",
            "Starting BFS exploration from node 2: {(InCol0 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 2: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/4 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 4 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 2/100 ===\n",
            "Planning graph with 4 nodes and 6 edges\n",
            "Starting BFS exploration from node 3: {(InCol1 robot0), (InRow1 robot0)}\n",
            "\n",
            "[1] Exploring from node 3: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/4 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 6 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 3/100 ===\n",
            "Planning graph with 4 nodes and 4 edges\n",
            "Starting BFS exploration from node 2: {(InCol1 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 2: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/4 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 4 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 4/100 ===\n",
            "Planning graph with 4 nodes and 4 edges\n",
            "Starting BFS exploration from node 1: {(InCol1 robot0), (InRow1 robot0)}\n",
            "\n",
            "[1] Exploring from node 1: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 1 → 3 (operator: MoveLeft_from_col1)\n",
            "    → Reached target node 3 in 2 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 1 → 0 (operator: MoveDown_from_row1)\n",
            "    → Reached target node 0 in 1 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 3: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 3\n",
            "\n",
            "[3] Exploring from node 0: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 3\n",
            "  Trying edge 0 → 2 (operator: MoveLeft_from_col1)\n",
            "    → Reached target node 2 in 2 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[4] Exploring from node 2: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 4\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 4/4 nodes\n",
            "Discovered 4 unique atom sets\n",
            "Total states collected: 4\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 4 edges\n",
            "BFS collected states for 4 atom sets\n",
            "\n",
            "=== Episode 5/100 ===\n",
            "Planning graph with 1 nodes and 0 edges\n",
            "Starting BFS exploration from node 0: {(InCol0 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 0: frozenset({(InCol0 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/1 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 1 nodes, 0 edges\n",
            "BFS collected states for 1 atom sets\n",
            "  Episode 5/100: 4 nodes, 8 edges\n",
            "\n",
            "=== Episode 6/100 ===\n",
            "Planning graph with 1 nodes and 0 edges\n",
            "Warning: Could not find node matching initial atoms: {(InRow1 robot0), (InCol0 robot0)}\n",
            "Episode graph has 1 nodes, 0 edges\n",
            "BFS collected states for 0 atom sets\n",
            "\n",
            "=== Episode 7/100 ===\n",
            "Planning graph with 3 nodes and 2 edges\n",
            "Warning: Could not find node matching initial atoms: {(InCol0 robot0), (InRow0 robot0)}\n",
            "Episode graph has 3 nodes, 2 edges\n",
            "BFS collected states for 0 atom sets\n",
            "\n",
            "=== Episode 8/100 ===\n",
            "Planning graph with 4 nodes and 4 edges\n",
            "Starting BFS exploration from node 2: {(InCol1 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 2: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/4 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 4 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 9/100 ===\n",
            "Planning graph with 1 nodes and 0 edges\n",
            "Warning: Could not find node matching initial atoms: {(InCol0 robot0), (InRow0 robot0)}\n",
            "Episode graph has 1 nodes, 0 edges\n",
            "BFS collected states for 0 atom sets\n",
            "\n",
            "=== Episode 10/100 ===\n",
            "Planning graph with 4 nodes and 4 edges\n",
            "Starting BFS exploration from node 0: {(InCol1 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 0: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 0 → 1 (operator: MoveUp_from_row0)\n",
            "    → Reached target node 1 in 1 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 0 → 2 (operator: MoveLeft_from_col1)\n",
            "    → Reached target node 2 in 3 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 1: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 1, Visited nodes: 3\n",
            "  Trying edge 1 → 3 (operator: MoveLeft_from_col1)\n",
            "    → Reached target node 3 in 3 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[3] Exploring from node 2: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 4\n",
            "\n",
            "[4] Exploring from node 3: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 4\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 4/4 nodes\n",
            "Discovered 4 unique atom sets\n",
            "Total states collected: 4\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 4 edges\n",
            "BFS collected states for 4 atom sets\n",
            "  Episode 10/100: 4 nodes, 8 edges\n",
            "\n",
            "=== Episode 11/100 ===\n",
            "Planning graph with 4 nodes and 6 edges\n",
            "Starting BFS exploration from node 3: {(InCol1 robot0), (InRow1 robot0)}\n",
            "\n",
            "[1] Exploring from node 3: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/4 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 6 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 12/100 ===\n",
            "Planning graph with 4 nodes and 6 edges\n",
            "Starting BFS exploration from node 2: {(InCol1 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 2: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 2 → 0 (operator: MoveUp_from_row0)\n",
            "    → Reached target node 0 in 2 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 2 → 3 (operator: MoveLeft_from_col1)\n",
            "    → Reached target node 3 in 5 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 0: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 1, Visited nodes: 3\n",
            "  Trying edge 0 → 1 (operator: MoveLeft_from_col1)\n",
            "    → Terminated/truncated at step 1\n",
            "    ✗ Failed to reach target node\n",
            "\n",
            "[3] Exploring from node 3: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 3\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 3/4 nodes\n",
            "Discovered 3 unique atom sets\n",
            "Total states collected: 3\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 6 edges\n",
            "BFS collected states for 3 atom sets\n",
            "\n",
            "=== Episode 13/100 ===\n",
            "Planning graph with 3 nodes and 2 edges\n",
            "Starting BFS exploration from node 2: {(InCol1 robot0), (InRow1 robot0)}\n",
            "\n",
            "[1] Exploring from node 2: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/3 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 3 nodes, 2 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 14/100 ===\n",
            "Planning graph with 4 nodes and 6 edges\n",
            "Starting BFS exploration from node 1: {(InCol1 robot0), (InRow1 robot0)}\n",
            "\n",
            "[1] Exploring from node 1: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 1 → 3 (operator: MoveLeft_from_col1)\n",
            "    → Reached target node 3 in 2 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 1 → 0 (operator: MoveDown_from_row1)\n",
            "    → Reached target node 0 in 1 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 3: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 3\n",
            "\n",
            "[3] Exploring from node 0: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 3\n",
            "  Trying edge 0 → 2 (operator: MoveLeft_from_col1)\n",
            "    → Terminated/truncated at step 1\n",
            "    ✗ Failed to reach target node\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 3/4 nodes\n",
            "Discovered 3 unique atom sets\n",
            "Total states collected: 3\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 6 edges\n",
            "BFS collected states for 3 atom sets\n",
            "\n",
            "=== Episode 15/100 ===\n",
            "Planning graph with 4 nodes and 4 edges\n",
            "Starting BFS exploration from node 0: {(InRow1 robot0), (InCol0 robot0)}\n",
            "\n",
            "[1] Exploring from node 0: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 0 → 1 (operator: MoveDown_from_row1)\n",
            "    → Reached target node 1 in 1 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 0 → 2 (operator: MoveRight_from_col0)\n",
            "    → Reached target node 2 in 1 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 1: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 3\n",
            "  Trying edge 1 → 3 (operator: MoveRight_from_col0)\n",
            "    → Reached target node 3 in 1 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[3] Exploring from node 2: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 1, Visited nodes: 4\n",
            "\n",
            "[4] Exploring from node 3: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 4\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 4/4 nodes\n",
            "Discovered 4 unique atom sets\n",
            "Total states collected: 4\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 4 edges\n",
            "BFS collected states for 4 atom sets\n",
            "  Episode 15/100: 4 nodes, 8 edges\n",
            "\n",
            "=== Episode 16/100 ===\n",
            "Planning graph with 3 nodes and 2 edges\n",
            "Starting BFS exploration from node 0: {(InRow1 robot0), (InCol0 robot0)}\n",
            "\n",
            "[1] Exploring from node 0: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 0 → 1 (operator: MoveDown_from_row1)\n",
            "    → Reached target node 1 in 2 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 0 → 2 (operator: MoveRight_from_col0)\n",
            "    → Reached target node 2 in 5 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 1: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 3\n",
            "\n",
            "[3] Exploring from node 2: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 0, Visited nodes: 3\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 3/3 nodes\n",
            "Discovered 3 unique atom sets\n",
            "Total states collected: 3\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 3 nodes, 2 edges\n",
            "BFS collected states for 3 atom sets\n",
            "\n",
            "=== Episode 17/100 ===\n",
            "Planning graph with 3 nodes and 2 edges\n",
            "Warning: Could not find node matching initial atoms: {(InRow1 robot0), (InCol0 robot0)}\n",
            "Episode graph has 3 nodes, 2 edges\n",
            "BFS collected states for 0 atom sets\n",
            "\n",
            "=== Episode 18/100 ===\n",
            "Planning graph with 1 nodes and 0 edges\n",
            "Starting BFS exploration from node 0: {(InCol1 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 0: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/1 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 1 nodes, 0 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 19/100 ===\n",
            "Planning graph with 4 nodes and 4 edges\n",
            "Starting BFS exploration from node 3: {(InCol1 robot0), (InRow1 robot0)}\n",
            "\n",
            "[1] Exploring from node 3: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/4 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 4 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 20/100 ===\n",
            "Planning graph with 3 nodes and 2 edges\n",
            "Warning: Could not find node matching initial atoms: {(InCol1 robot0), (InRow1 robot0)}\n",
            "Episode graph has 3 nodes, 2 edges\n",
            "BFS collected states for 0 atom sets\n",
            "  Episode 20/100: 4 nodes, 8 edges\n",
            "\n",
            "=== Episode 21/100 ===\n",
            "Planning graph with 4 nodes and 6 edges\n",
            "Starting BFS exploration from node 0: {(InRow1 robot0), (InCol0 robot0)}\n",
            "\n",
            "[1] Exploring from node 0: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 0 → 1 (operator: MoveDown_from_row1)\n",
            "    → Terminated/truncated at step 1\n",
            "    ✗ Failed to reach target node\n",
            "  Trying edge 0 → 2 (operator: MoveRight_from_col0)\n",
            "    → Terminated/truncated at step 1\n",
            "    ✗ Failed to reach target node\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/4 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 6 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 22/100 ===\n",
            "Planning graph with 3 nodes and 2 edges\n",
            "Starting BFS exploration from node 0: {(InRow1 robot0), (InCol0 robot0)}\n",
            "\n",
            "[1] Exploring from node 0: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 0 → 1 (operator: MoveDown_from_row1)\n",
            "    → Reached target node 1 in 3 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 0 → 2 (operator: MoveRight_from_col0)\n",
            "    → Reached target node 2 in 5 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 1: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 3\n",
            "\n",
            "[3] Exploring from node 2: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 0, Visited nodes: 3\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 3/3 nodes\n",
            "Discovered 3 unique atom sets\n",
            "Total states collected: 3\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 3 nodes, 2 edges\n",
            "BFS collected states for 3 atom sets\n",
            "\n",
            "=== Episode 23/100 ===\n",
            "Planning graph with 4 nodes and 6 edges\n",
            "Starting BFS exploration from node 2: {(InCol0 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 2: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 2 → 3 (operator: MoveUp_from_row0)\n",
            "    → Reached target node 3 in 2 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 2 → 0 (operator: MoveRight_from_col0)\n",
            "    → Reached target node 0 in 3 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 3: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 3\n",
            "\n",
            "[3] Exploring from node 0: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 3\n",
            "  Trying edge 0 → 1 (operator: MoveUp_from_row0)\n",
            "    → Reached target node 1 in 2 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[4] Exploring from node 1: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 0, Visited nodes: 4\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 4/4 nodes\n",
            "Discovered 4 unique atom sets\n",
            "Total states collected: 4\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 6 edges\n",
            "BFS collected states for 4 atom sets\n",
            "\n",
            "=== Episode 24/100 ===\n",
            "Planning graph with 4 nodes and 6 edges\n",
            "Starting BFS exploration from node 2: {(InCol1 robot0), (InRow1 robot0)}\n",
            "\n",
            "[1] Exploring from node 2: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 2 → 0 (operator: MoveLeft_from_col1)\n",
            "    → Reached target node 0 in 5 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 2 → 3 (operator: MoveDown_from_row1)\n",
            "    → Reached target node 3 in 5 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 0: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 3\n",
            "  Trying edge 0 → 1 (operator: MoveDown_from_row1)\n",
            "    → Reached target node 1 in 5 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[3] Exploring from node 3: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 4\n",
            "\n",
            "[4] Exploring from node 1: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 4\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 4/4 nodes\n",
            "Discovered 4 unique atom sets\n",
            "Total states collected: 4\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 6 edges\n",
            "BFS collected states for 4 atom sets\n",
            "\n",
            "=== Episode 25/100 ===\n",
            "Planning graph with 1 nodes and 0 edges\n",
            "Warning: Could not find node matching initial atoms: {(InCol1 robot0), (InRow0 robot0)}\n",
            "Episode graph has 1 nodes, 0 edges\n",
            "BFS collected states for 0 atom sets\n",
            "  Episode 25/100: 4 nodes, 8 edges\n",
            "\n",
            "=== Episode 26/100 ===\n",
            "Planning graph with 3 nodes and 2 edges\n",
            "Starting BFS exploration from node 1: {(InCol0 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 1: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/3 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 3 nodes, 2 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 27/100 ===\n",
            "Planning graph with 4 nodes and 6 edges\n",
            "Starting BFS exploration from node 0: {(InCol0 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 0: frozenset({(InCol0 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 0 → 1 (operator: MoveUp_from_row0)\n",
            "    → Reached target node 1 in 5 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 0 → 2 (operator: MoveRight_from_col0)\n",
            "    → Reached target node 2 in 5 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 1: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 3\n",
            "  Trying edge 1 → 3 (operator: MoveRight_from_col0)\n",
            "    → Reached target node 3 in 5 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[3] Exploring from node 2: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 4\n",
            "\n",
            "[4] Exploring from node 3: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 0, Visited nodes: 4\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 4/4 nodes\n",
            "Discovered 4 unique atom sets\n",
            "Total states collected: 4\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 6 edges\n",
            "BFS collected states for 4 atom sets\n",
            "\n",
            "=== Episode 28/100 ===\n",
            "Planning graph with 4 nodes and 6 edges\n",
            "Starting BFS exploration from node 2: {(InCol1 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 2: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 2 → 0 (operator: MoveUp_from_row0)\n",
            "    → Reached target node 0 in 5 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 2 → 3 (operator: MoveLeft_from_col1)\n",
            "    → Reached target node 3 in 4 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 0: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 1, Visited nodes: 3\n",
            "  Trying edge 0 → 1 (operator: MoveLeft_from_col1)\n",
            "    → Terminated/truncated at step 1\n",
            "    ✗ Failed to reach target node\n",
            "\n",
            "[3] Exploring from node 3: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 3\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 3/4 nodes\n",
            "Discovered 3 unique atom sets\n",
            "Total states collected: 3\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 6 edges\n",
            "BFS collected states for 3 atom sets\n",
            "\n",
            "=== Episode 29/100 ===\n",
            "Planning graph with 4 nodes and 4 edges\n",
            "Starting BFS exploration from node 1: {(InCol1 robot0), (InRow1 robot0)}\n",
            "\n",
            "[1] Exploring from node 1: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 1 → 3 (operator: MoveLeft_from_col1)\n",
            "    → Terminated/truncated at step 1\n",
            "    ✗ Failed to reach target node\n",
            "  Trying edge 1 → 0 (operator: MoveDown_from_row1)\n",
            "    → Terminated/truncated at step 1\n",
            "    ✗ Failed to reach target node\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/4 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 4 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 30/100 ===\n",
            "Planning graph with 3 nodes and 2 edges\n",
            "Warning: Could not find node matching initial atoms: {(InCol1 robot0), (InRow0 robot0)}\n",
            "Episode graph has 3 nodes, 2 edges\n",
            "BFS collected states for 0 atom sets\n",
            "  Episode 30/100: 4 nodes, 8 edges\n",
            "\n",
            "=== Episode 31/100 ===\n",
            "Planning graph with 4 nodes and 6 edges\n",
            "Starting BFS exploration from node 0: {(InCol1 robot0), (InRow1 robot0)}\n",
            "\n",
            "[1] Exploring from node 0: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 0 → 1 (operator: MoveLeft_from_col1)\n",
            "    → Reached target node 1 in 3 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 0 → 2 (operator: MoveDown_from_row1)\n",
            "    → Reached target node 2 in 5 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 1: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 3\n",
            "  Trying edge 1 → 3 (operator: MoveDown_from_row1)\n",
            "    → Reached target node 3 in 5 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[3] Exploring from node 2: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 4\n",
            "\n",
            "[4] Exploring from node 3: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 4\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 4/4 nodes\n",
            "Discovered 4 unique atom sets\n",
            "Total states collected: 4\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 6 edges\n",
            "BFS collected states for 4 atom sets\n",
            "\n",
            "=== Episode 32/100 ===\n",
            "Planning graph with 4 nodes and 4 edges\n",
            "Starting BFS exploration from node 1: {(InRow1 robot0), (InCol0 robot0)}\n",
            "\n",
            "[1] Exploring from node 1: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 1 → 3 (operator: MoveDown_from_row1)\n",
            "    → Terminated/truncated at step 1\n",
            "    ✗ Failed to reach target node\n",
            "  Trying edge 1 → 0 (operator: MoveRight_from_col0)\n",
            "    → Reached target node 0 in 1 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 0: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 0, Visited nodes: 2\n",
            "  Trying edge 0 → 2 (operator: MoveDown_from_row1)\n",
            "    → Reached target node 2 in 3 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[3] Exploring from node 2: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 3\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 3/4 nodes\n",
            "Discovered 3 unique atom sets\n",
            "Total states collected: 3\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 4 edges\n",
            "BFS collected states for 3 atom sets\n",
            "\n",
            "=== Episode 33/100 ===\n",
            "Planning graph with 1 nodes and 0 edges\n",
            "Starting BFS exploration from node 0: {(InCol0 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 0: frozenset({(InCol0 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/1 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 1 nodes, 0 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 34/100 ===\n",
            "Planning graph with 4 nodes and 4 edges\n",
            "Starting BFS exploration from node 1: {(InCol0 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 1: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 1 → 0 (operator: MoveUp_from_row0)\n",
            "    → Reached target node 0 in 1 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 1 → 3 (operator: MoveRight_from_col0)\n",
            "    → Terminated/truncated at step 1\n",
            "    ✗ Failed to reach target node\n",
            "\n",
            "[2] Exploring from node 0: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 2\n",
            "  Trying edge 0 → 2 (operator: MoveRight_from_col0)\n",
            "    → Reached target node 2 in 4 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[3] Exploring from node 2: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 0, Visited nodes: 3\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 3/4 nodes\n",
            "Discovered 3 unique atom sets\n",
            "Total states collected: 3\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 4 edges\n",
            "BFS collected states for 3 atom sets\n",
            "\n",
            "=== Episode 35/100 ===\n",
            "Planning graph with 4 nodes and 6 edges\n",
            "Starting BFS exploration from node 1: {(InRow1 robot0), (InCol0 robot0)}\n",
            "\n",
            "[1] Exploring from node 1: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 1 → 3 (operator: MoveDown_from_row1)\n",
            "    → Reached target node 3 in 5 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 1 → 0 (operator: MoveRight_from_col0)\n",
            "    → Reached target node 0 in 5 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 3: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 3\n",
            "\n",
            "[3] Exploring from node 0: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 0, Visited nodes: 3\n",
            "  Trying edge 0 → 2 (operator: MoveDown_from_row1)\n",
            "    → Reached target node 2 in 5 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[4] Exploring from node 2: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 4\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 4/4 nodes\n",
            "Discovered 4 unique atom sets\n",
            "Total states collected: 4\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 6 edges\n",
            "BFS collected states for 4 atom sets\n",
            "  Episode 35/100: 4 nodes, 8 edges\n",
            "\n",
            "=== Episode 36/100 ===\n",
            "Planning graph with 3 nodes and 2 edges\n",
            "Warning: Could not find node matching initial atoms: {(InCol1 robot0), (InRow0 robot0)}\n",
            "Episode graph has 3 nodes, 2 edges\n",
            "BFS collected states for 0 atom sets\n",
            "\n",
            "=== Episode 37/100 ===\n",
            "Planning graph with 3 nodes and 2 edges\n",
            "Warning: Could not find node matching initial atoms: {(InRow1 robot0), (InCol0 robot0)}\n",
            "Episode graph has 3 nodes, 2 edges\n",
            "BFS collected states for 0 atom sets\n",
            "\n",
            "=== Episode 38/100 ===\n",
            "Planning graph with 1 nodes and 0 edges\n",
            "Warning: Could not find node matching initial atoms: {(InCol1 robot0), (InRow0 robot0)}\n",
            "Episode graph has 1 nodes, 0 edges\n",
            "BFS collected states for 0 atom sets\n",
            "\n",
            "=== Episode 39/100 ===\n",
            "Planning graph with 3 nodes and 2 edges\n",
            "Starting BFS exploration from node 1: {(InRow1 robot0), (InCol0 robot0)}\n",
            "\n",
            "[1] Exploring from node 1: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/3 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 3 nodes, 2 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 40/100 ===\n",
            "Planning graph with 4 nodes and 6 edges\n",
            "Starting BFS exploration from node 1: {(InCol1 robot0), (InRow1 robot0)}\n",
            "\n",
            "[1] Exploring from node 1: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 1 → 3 (operator: MoveLeft_from_col1)\n",
            "    → Reached target node 3 in 2 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 1 → 0 (operator: MoveDown_from_row1)\n",
            "    → Reached target node 0 in 4 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 3: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 3\n",
            "\n",
            "[3] Exploring from node 0: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 3\n",
            "  Trying edge 0 → 2 (operator: MoveLeft_from_col1)\n",
            "    → Reached target node 2 in 2 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[4] Exploring from node 2: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 4\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 4/4 nodes\n",
            "Discovered 4 unique atom sets\n",
            "Total states collected: 4\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 6 edges\n",
            "BFS collected states for 4 atom sets\n",
            "  Episode 40/100: 4 nodes, 8 edges\n",
            "\n",
            "=== Episode 41/100 ===\n",
            "Planning graph with 4 nodes and 4 edges\n",
            "Starting BFS exploration from node 3: {(InCol0 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 3: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/4 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 4 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 42/100 ===\n",
            "Planning graph with 3 nodes and 2 edges\n",
            "Starting BFS exploration from node 1: {(InRow1 robot0), (InCol0 robot0)}\n",
            "\n",
            "[1] Exploring from node 1: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/3 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 3 nodes, 2 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 43/100 ===\n",
            "Planning graph with 4 nodes and 6 edges\n",
            "Starting BFS exploration from node 2: {(InCol1 robot0), (InRow1 robot0)}\n",
            "\n",
            "[1] Exploring from node 2: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 2 → 0 (operator: MoveLeft_from_col1)\n",
            "    → Reached target node 0 in 4 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 2 → 3 (operator: MoveDown_from_row1)\n",
            "    → Reached target node 3 in 2 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 0: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 3\n",
            "  Trying edge 0 → 1 (operator: MoveDown_from_row1)\n",
            "    → Terminated/truncated at step 1\n",
            "    ✗ Failed to reach target node\n",
            "\n",
            "[3] Exploring from node 3: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 3\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 3/4 nodes\n",
            "Discovered 3 unique atom sets\n",
            "Total states collected: 3\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 6 edges\n",
            "BFS collected states for 3 atom sets\n",
            "\n",
            "=== Episode 44/100 ===\n",
            "Planning graph with 1 nodes and 0 edges\n",
            "Warning: Could not find node matching initial atoms: {(InCol1 robot0), (InRow1 robot0)}\n",
            "Episode graph has 1 nodes, 0 edges\n",
            "BFS collected states for 0 atom sets\n",
            "\n",
            "=== Episode 45/100 ===\n",
            "Planning graph with 1 nodes and 0 edges\n",
            "Warning: Could not find node matching initial atoms: {(InRow1 robot0), (InCol0 robot0)}\n",
            "Episode graph has 1 nodes, 0 edges\n",
            "BFS collected states for 0 atom sets\n",
            "  Episode 45/100: 4 nodes, 8 edges\n",
            "\n",
            "=== Episode 46/100 ===\n",
            "Planning graph with 4 nodes and 4 edges\n",
            "Starting BFS exploration from node 2: {(InCol1 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 2: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/4 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 4 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 47/100 ===\n",
            "Planning graph with 3 nodes and 2 edges\n",
            "Starting BFS exploration from node 0: {(InCol0 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 0: frozenset({(InCol0 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 0 → 1 (operator: MoveUp_from_row0)\n",
            "    → Reached target node 1 in 5 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 0 → 2 (operator: MoveRight_from_col0)\n",
            "    → Reached target node 2 in 5 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 1: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 3\n",
            "\n",
            "[3] Exploring from node 2: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 3\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 3/3 nodes\n",
            "Discovered 3 unique atom sets\n",
            "Total states collected: 3\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 3 nodes, 2 edges\n",
            "BFS collected states for 3 atom sets\n",
            "\n",
            "=== Episode 48/100 ===\n",
            "Planning graph with 3 nodes and 2 edges\n",
            "Starting BFS exploration from node 0: {(InCol1 robot0), (InRow1 robot0)}\n",
            "\n",
            "[1] Exploring from node 0: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 0 → 1 (operator: MoveLeft_from_col1)\n",
            "    → Reached target node 1 in 1 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 0 → 2 (operator: MoveDown_from_row1)\n",
            "    → Reached target node 2 in 2 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 1: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 3\n",
            "\n",
            "[3] Exploring from node 2: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 3\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 3/3 nodes\n",
            "Discovered 3 unique atom sets\n",
            "Total states collected: 3\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 3 nodes, 2 edges\n",
            "BFS collected states for 3 atom sets\n",
            "\n",
            "=== Episode 49/100 ===\n",
            "Planning graph with 3 nodes and 2 edges\n",
            "Starting BFS exploration from node 1: {(InCol1 robot0), (InRow1 robot0)}\n",
            "\n",
            "[1] Exploring from node 1: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/3 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 3 nodes, 2 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 50/100 ===\n",
            "Planning graph with 4 nodes and 4 edges\n",
            "Starting BFS exploration from node 0: {(InRow1 robot0), (InCol0 robot0)}\n",
            "\n",
            "[1] Exploring from node 0: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 0 → 1 (operator: MoveDown_from_row1)\n",
            "    → Reached target node 1 in 1 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 0 → 2 (operator: MoveRight_from_col0)\n",
            "    → Reached target node 2 in 3 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 1: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 3\n",
            "  Trying edge 1 → 3 (operator: MoveRight_from_col0)\n",
            "    → Reached target node 3 in 3 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[3] Exploring from node 2: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 1, Visited nodes: 4\n",
            "\n",
            "[4] Exploring from node 3: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 4\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 4/4 nodes\n",
            "Discovered 4 unique atom sets\n",
            "Total states collected: 4\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 4 edges\n",
            "BFS collected states for 4 atom sets\n",
            "  Episode 50/100: 4 nodes, 8 edges\n",
            "\n",
            "=== Episode 51/100 ===\n",
            "Planning graph with 4 nodes and 4 edges\n",
            "Starting BFS exploration from node 0: {(InCol1 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 0: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 0 → 1 (operator: MoveUp_from_row0)\n",
            "    → Reached target node 1 in 1 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 0 → 2 (operator: MoveLeft_from_col1)\n",
            "    → Reached target node 2 in 4 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 1: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 1, Visited nodes: 3\n",
            "  Trying edge 1 → 3 (operator: MoveLeft_from_col1)\n",
            "    → Reached target node 3 in 4 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[3] Exploring from node 2: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 4\n",
            "\n",
            "[4] Exploring from node 3: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 4\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 4/4 nodes\n",
            "Discovered 4 unique atom sets\n",
            "Total states collected: 4\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 4 edges\n",
            "BFS collected states for 4 atom sets\n",
            "\n",
            "=== Episode 52/100 ===\n",
            "Planning graph with 1 nodes and 0 edges\n",
            "Warning: Could not find node matching initial atoms: {(InCol1 robot0), (InRow1 robot0)}\n",
            "Episode graph has 1 nodes, 0 edges\n",
            "BFS collected states for 0 atom sets\n",
            "\n",
            "=== Episode 53/100 ===\n",
            "Planning graph with 3 nodes and 2 edges\n",
            "Warning: Could not find node matching initial atoms: {(InCol1 robot0), (InRow1 robot0)}\n",
            "Episode graph has 3 nodes, 2 edges\n",
            "BFS collected states for 0 atom sets\n",
            "\n",
            "=== Episode 54/100 ===\n",
            "Planning graph with 1 nodes and 0 edges\n",
            "Warning: Could not find node matching initial atoms: {(InCol1 robot0), (InRow1 robot0)}\n",
            "Episode graph has 1 nodes, 0 edges\n",
            "BFS collected states for 0 atom sets\n",
            "\n",
            "=== Episode 55/100 ===\n",
            "Planning graph with 4 nodes and 6 edges\n",
            "Starting BFS exploration from node 0: {(InCol1 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 0: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 0 → 1 (operator: MoveUp_from_row0)\n",
            "    → Terminated/truncated at step 1\n",
            "    ✗ Failed to reach target node\n",
            "  Trying edge 0 → 2 (operator: MoveLeft_from_col1)\n",
            "    → Reached target node 2 in 1 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 2: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 2\n",
            "  Trying edge 2 → 3 (operator: MoveUp_from_row0)\n",
            "    → Reached target node 3 in 5 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[3] Exploring from node 3: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 3\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 3/4 nodes\n",
            "Discovered 3 unique atom sets\n",
            "Total states collected: 3\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 6 edges\n",
            "BFS collected states for 3 atom sets\n",
            "  Episode 55/100: 4 nodes, 8 edges\n",
            "\n",
            "=== Episode 56/100 ===\n",
            "Planning graph with 4 nodes and 6 edges\n",
            "Starting BFS exploration from node 2: {(InCol1 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 2: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 2 → 0 (operator: MoveUp_from_row0)\n",
            "    → Reached target node 0 in 1 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 2 → 3 (operator: MoveLeft_from_col1)\n",
            "    → Reached target node 3 in 2 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 0: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 1, Visited nodes: 3\n",
            "  Trying edge 0 → 1 (operator: MoveLeft_from_col1)\n",
            "    → Reached target node 1 in 2 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[3] Exploring from node 3: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 4\n",
            "\n",
            "[4] Exploring from node 1: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 4\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 4/4 nodes\n",
            "Discovered 4 unique atom sets\n",
            "Total states collected: 4\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 6 edges\n",
            "BFS collected states for 4 atom sets\n",
            "\n",
            "=== Episode 57/100 ===\n",
            "Planning graph with 3 nodes and 2 edges\n",
            "Starting BFS exploration from node 2: {(InCol1 robot0), (InRow1 robot0)}\n",
            "\n",
            "[1] Exploring from node 2: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/3 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 3 nodes, 2 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 58/100 ===\n",
            "Planning graph with 4 nodes and 6 edges\n",
            "Starting BFS exploration from node 0: {(InRow1 robot0), (InCol0 robot0)}\n",
            "\n",
            "[1] Exploring from node 0: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 0 → 1 (operator: MoveDown_from_row1)\n",
            "    → Reached target node 1 in 3 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 0 → 2 (operator: MoveRight_from_col0)\n",
            "    → Reached target node 2 in 1 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 1: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 3\n",
            "  Trying edge 1 → 3 (operator: MoveRight_from_col0)\n",
            "    → Reached target node 3 in 1 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[3] Exploring from node 2: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 1, Visited nodes: 4\n",
            "\n",
            "[4] Exploring from node 3: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 4\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 4/4 nodes\n",
            "Discovered 4 unique atom sets\n",
            "Total states collected: 4\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 6 edges\n",
            "BFS collected states for 4 atom sets\n",
            "\n",
            "=== Episode 59/100 ===\n",
            "Planning graph with 4 nodes and 4 edges\n",
            "Starting BFS exploration from node 0: {(InCol1 robot0), (InRow1 robot0)}\n",
            "\n",
            "[1] Exploring from node 0: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 0 → 1 (operator: MoveLeft_from_col1)\n",
            "    → Reached target node 1 in 2 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 0 → 2 (operator: MoveDown_from_row1)\n",
            "    → Reached target node 2 in 5 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 1: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 3\n",
            "  Trying edge 1 → 3 (operator: MoveDown_from_row1)\n",
            "    → Reached target node 3 in 5 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[3] Exploring from node 2: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 4\n",
            "\n",
            "[4] Exploring from node 3: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 4\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 4/4 nodes\n",
            "Discovered 4 unique atom sets\n",
            "Total states collected: 4\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 4 edges\n",
            "BFS collected states for 4 atom sets\n",
            "\n",
            "=== Episode 60/100 ===\n",
            "Planning graph with 4 nodes and 4 edges\n",
            "Starting BFS exploration from node 2: {(InCol0 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 2: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/4 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 4 edges\n",
            "BFS collected states for 1 atom sets\n",
            "  Episode 60/100: 4 nodes, 8 edges\n",
            "\n",
            "=== Episode 61/100 ===\n",
            "Planning graph with 1 nodes and 0 edges\n",
            "Warning: Could not find node matching initial atoms: {(InCol0 robot0), (InRow0 robot0)}\n",
            "Episode graph has 1 nodes, 0 edges\n",
            "BFS collected states for 0 atom sets\n",
            "\n",
            "=== Episode 62/100 ===\n",
            "Planning graph with 1 nodes and 0 edges\n",
            "Warning: Could not find node matching initial atoms: {(InCol1 robot0), (InRow1 robot0)}\n",
            "Episode graph has 1 nodes, 0 edges\n",
            "BFS collected states for 0 atom sets\n",
            "\n",
            "=== Episode 63/100 ===\n",
            "Planning graph with 4 nodes and 4 edges\n",
            "Starting BFS exploration from node 1: {(InRow1 robot0), (InCol0 robot0)}\n",
            "\n",
            "[1] Exploring from node 1: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 1 → 0 (operator: MoveDown_from_row1)\n",
            "    → Terminated/truncated at step 1\n",
            "    ✗ Failed to reach target node\n",
            "  Trying edge 1 → 3 (operator: MoveRight_from_col0)\n",
            "    → Terminated/truncated at step 1\n",
            "    ✗ Failed to reach target node\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/4 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 4 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 64/100 ===\n",
            "Planning graph with 3 nodes and 2 edges\n",
            "Starting BFS exploration from node 2: {(InCol0 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 2: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/3 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 3 nodes, 2 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 65/100 ===\n",
            "Planning graph with 4 nodes and 6 edges\n",
            "Starting BFS exploration from node 0: {(InCol1 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 0: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 0 → 1 (operator: MoveUp_from_row0)\n",
            "    → Reached target node 1 in 3 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 0 → 2 (operator: MoveLeft_from_col1)\n",
            "    → Reached target node 2 in 4 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 1: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 1, Visited nodes: 3\n",
            "  Trying edge 1 → 3 (operator: MoveLeft_from_col1)\n",
            "    → Reached target node 3 in 4 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[3] Exploring from node 2: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 4\n",
            "\n",
            "[4] Exploring from node 3: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 4\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 4/4 nodes\n",
            "Discovered 4 unique atom sets\n",
            "Total states collected: 4\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 6 edges\n",
            "BFS collected states for 4 atom sets\n",
            "  Episode 65/100: 4 nodes, 8 edges\n",
            "\n",
            "=== Episode 66/100 ===\n",
            "Planning graph with 4 nodes and 6 edges\n",
            "Starting BFS exploration from node 3: {(InRow1 robot0), (InCol0 robot0)}\n",
            "\n",
            "[1] Exploring from node 3: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/4 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 6 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 67/100 ===\n",
            "Planning graph with 4 nodes and 4 edges\n",
            "Starting BFS exploration from node 1: {(InCol0 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 1: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 1 → 0 (operator: MoveUp_from_row0)\n",
            "    → Reached target node 0 in 4 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 1 → 3 (operator: MoveRight_from_col0)\n",
            "    → Reached target node 3 in 4 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 0: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 3\n",
            "  Trying edge 0 → 2 (operator: MoveRight_from_col0)\n",
            "    → Reached target node 2 in 4 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[3] Exploring from node 3: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 4\n",
            "\n",
            "[4] Exploring from node 2: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 0, Visited nodes: 4\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 4/4 nodes\n",
            "Discovered 4 unique atom sets\n",
            "Total states collected: 4\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 4 edges\n",
            "BFS collected states for 4 atom sets\n",
            "\n",
            "=== Episode 68/100 ===\n",
            "Planning graph with 3 nodes and 2 edges\n",
            "Starting BFS exploration from node 1: {(InCol0 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 1: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/3 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 3 nodes, 2 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 69/100 ===\n",
            "Planning graph with 4 nodes and 4 edges\n",
            "Starting BFS exploration from node 1: {(InRow1 robot0), (InCol0 robot0)}\n",
            "\n",
            "[1] Exploring from node 1: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 1 → 3 (operator: MoveDown_from_row1)\n",
            "    → Reached target node 3 in 3 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 1 → 0 (operator: MoveRight_from_col0)\n",
            "    → Reached target node 0 in 5 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 3: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 3\n",
            "\n",
            "[3] Exploring from node 0: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 0, Visited nodes: 3\n",
            "  Trying edge 0 → 2 (operator: MoveDown_from_row1)\n",
            "    → Reached target node 2 in 3 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[4] Exploring from node 2: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 4\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 4/4 nodes\n",
            "Discovered 4 unique atom sets\n",
            "Total states collected: 4\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 4 edges\n",
            "BFS collected states for 4 atom sets\n",
            "\n",
            "=== Episode 70/100 ===\n",
            "Planning graph with 1 nodes and 0 edges\n",
            "Warning: Could not find node matching initial atoms: {(InCol0 robot0), (InRow0 robot0)}\n",
            "Episode graph has 1 nodes, 0 edges\n",
            "BFS collected states for 0 atom sets\n",
            "  Episode 70/100: 4 nodes, 8 edges\n",
            "\n",
            "=== Episode 71/100 ===\n",
            "Planning graph with 3 nodes and 2 edges\n",
            "Starting BFS exploration from node 1: {(InCol0 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 1: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/3 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 3 nodes, 2 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 72/100 ===\n",
            "Planning graph with 3 nodes and 2 edges\n",
            "Warning: Could not find node matching initial atoms: {(InCol1 robot0), (InRow1 robot0)}\n",
            "Episode graph has 3 nodes, 2 edges\n",
            "BFS collected states for 0 atom sets\n",
            "\n",
            "=== Episode 73/100 ===\n",
            "Planning graph with 4 nodes and 4 edges\n",
            "Starting BFS exploration from node 3: {(InCol1 robot0), (InRow1 robot0)}\n",
            "\n",
            "[1] Exploring from node 3: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/4 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 4 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 74/100 ===\n",
            "Planning graph with 4 nodes and 4 edges\n",
            "Starting BFS exploration from node 0: {(InCol1 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 0: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 0 → 1 (operator: MoveUp_from_row0)\n",
            "    → Terminated/truncated at step 1\n",
            "    ✗ Failed to reach target node\n",
            "  Trying edge 0 → 2 (operator: MoveLeft_from_col1)\n",
            "    → Terminated/truncated at step 1\n",
            "    ✗ Failed to reach target node\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/4 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 4 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 75/100 ===\n",
            "Planning graph with 4 nodes and 4 edges\n",
            "Starting BFS exploration from node 1: {(InRow1 robot0), (InCol0 robot0)}\n",
            "\n",
            "[1] Exploring from node 1: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 1 → 0 (operator: MoveDown_from_row1)\n",
            "    → Reached target node 0 in 1 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 1 → 3 (operator: MoveRight_from_col0)\n",
            "    → Reached target node 3 in 1 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 0: frozenset({(InCol0 robot0), (InRow0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 3\n",
            "  Trying edge 0 → 2 (operator: MoveRight_from_col0)\n",
            "    → Reached target node 2 in 1 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[3] Exploring from node 3: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 1, Visited nodes: 4\n",
            "\n",
            "[4] Exploring from node 2: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 4\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 4/4 nodes\n",
            "Discovered 4 unique atom sets\n",
            "Total states collected: 4\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 4 edges\n",
            "BFS collected states for 4 atom sets\n",
            "  Episode 75/100: 4 nodes, 8 edges\n",
            "\n",
            "=== Episode 76/100 ===\n",
            "Planning graph with 3 nodes and 2 edges\n",
            "Warning: Could not find node matching initial atoms: {(InCol1 robot0), (InRow1 robot0)}\n",
            "Episode graph has 3 nodes, 2 edges\n",
            "BFS collected states for 0 atom sets\n",
            "\n",
            "=== Episode 77/100 ===\n",
            "Planning graph with 1 nodes and 0 edges\n",
            "Warning: Could not find node matching initial atoms: {(InCol0 robot0), (InRow0 robot0)}\n",
            "Episode graph has 1 nodes, 0 edges\n",
            "BFS collected states for 0 atom sets\n",
            "\n",
            "=== Episode 78/100 ===\n",
            "Planning graph with 4 nodes and 6 edges\n",
            "Starting BFS exploration from node 2: {(InCol0 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 2: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 2 → 3 (operator: MoveUp_from_row0)\n",
            "    → Reached target node 3 in 5 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 2 → 0 (operator: MoveRight_from_col0)\n",
            "    → Reached target node 0 in 4 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 3: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 3\n",
            "\n",
            "[3] Exploring from node 0: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 3\n",
            "  Trying edge 0 → 1 (operator: MoveUp_from_row0)\n",
            "    → Reached target node 1 in 5 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[4] Exploring from node 1: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 0, Visited nodes: 4\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 4/4 nodes\n",
            "Discovered 4 unique atom sets\n",
            "Total states collected: 4\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 6 edges\n",
            "BFS collected states for 4 atom sets\n",
            "\n",
            "=== Episode 79/100 ===\n",
            "Planning graph with 4 nodes and 4 edges\n",
            "Starting BFS exploration from node 3: {(InCol1 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 3: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/4 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 4 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 80/100 ===\n",
            "Planning graph with 4 nodes and 4 edges\n",
            "Starting BFS exploration from node 0: {(InCol1 robot0), (InRow1 robot0)}\n",
            "\n",
            "[1] Exploring from node 0: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 0 → 1 (operator: MoveLeft_from_col1)\n",
            "    → Reached target node 1 in 2 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 0 → 2 (operator: MoveDown_from_row1)\n",
            "    → Reached target node 2 in 2 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 1: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 3\n",
            "  Trying edge 1 → 3 (operator: MoveDown_from_row1)\n",
            "    → Reached target node 3 in 2 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[3] Exploring from node 2: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 4\n",
            "\n",
            "[4] Exploring from node 3: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 4\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 4/4 nodes\n",
            "Discovered 4 unique atom sets\n",
            "Total states collected: 4\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 4 edges\n",
            "BFS collected states for 4 atom sets\n",
            "  Episode 80/100: 4 nodes, 8 edges\n",
            "\n",
            "=== Episode 81/100 ===\n",
            "Planning graph with 4 nodes and 6 edges\n",
            "Starting BFS exploration from node 1: {(InRow1 robot0), (InCol0 robot0)}\n",
            "\n",
            "[1] Exploring from node 1: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 1 → 0 (operator: MoveDown_from_row1)\n",
            "    → Reached target node 0 in 5 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 1 → 3 (operator: MoveRight_from_col0)\n",
            "    → Reached target node 3 in 3 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 0: frozenset({(InCol0 robot0), (InRow0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 3\n",
            "  Trying edge 0 → 2 (operator: MoveRight_from_col0)\n",
            "    → Reached target node 2 in 3 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[3] Exploring from node 3: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 1, Visited nodes: 4\n",
            "\n",
            "[4] Exploring from node 2: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 4\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 4/4 nodes\n",
            "Discovered 4 unique atom sets\n",
            "Total states collected: 4\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 6 edges\n",
            "BFS collected states for 4 atom sets\n",
            "\n",
            "=== Episode 82/100 ===\n",
            "Planning graph with 4 nodes and 6 edges\n",
            "Starting BFS exploration from node 3: {(InRow1 robot0), (InCol0 robot0)}\n",
            "\n",
            "[1] Exploring from node 3: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/4 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 6 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 83/100 ===\n",
            "Planning graph with 4 nodes and 6 edges\n",
            "Starting BFS exploration from node 0: {(InRow1 robot0), (InCol0 robot0)}\n",
            "\n",
            "[1] Exploring from node 0: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 0 → 1 (operator: MoveDown_from_row1)\n",
            "    → Reached target node 1 in 5 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 0 → 2 (operator: MoveRight_from_col0)\n",
            "    → Reached target node 2 in 5 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 1: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 3\n",
            "  Trying edge 1 → 3 (operator: MoveRight_from_col0)\n",
            "    → Terminated/truncated at step 1\n",
            "    ✗ Failed to reach target node\n",
            "\n",
            "[3] Exploring from node 2: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 0, Visited nodes: 3\n",
            "  Trying edge 2 → 3 (operator: MoveDown_from_row1)\n",
            "    → Reached target node 3 in 5 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[4] Exploring from node 3: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 4\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 4/4 nodes\n",
            "Discovered 4 unique atom sets\n",
            "Total states collected: 4\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 6 edges\n",
            "BFS collected states for 4 atom sets\n",
            "\n",
            "=== Episode 84/100 ===\n",
            "Planning graph with 4 nodes and 4 edges\n",
            "Starting BFS exploration from node 1: {(InCol0 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 1: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 1 → 0 (operator: MoveUp_from_row0)\n",
            "    → Reached target node 0 in 5 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 1 → 3 (operator: MoveRight_from_col0)\n",
            "    → Reached target node 3 in 1 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 0: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 3\n",
            "  Trying edge 0 → 2 (operator: MoveRight_from_col0)\n",
            "    → Reached target node 2 in 1 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[3] Exploring from node 3: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 4\n",
            "\n",
            "[4] Exploring from node 2: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 0, Visited nodes: 4\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 4/4 nodes\n",
            "Discovered 4 unique atom sets\n",
            "Total states collected: 4\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 4 edges\n",
            "BFS collected states for 4 atom sets\n",
            "\n",
            "=== Episode 85/100 ===\n",
            "Planning graph with 1 nodes and 0 edges\n",
            "Warning: Could not find node matching initial atoms: {(InRow1 robot0), (InCol0 robot0)}\n",
            "Episode graph has 1 nodes, 0 edges\n",
            "BFS collected states for 0 atom sets\n",
            "  Episode 85/100: 4 nodes, 8 edges\n",
            "\n",
            "=== Episode 86/100 ===\n",
            "Planning graph with 3 nodes and 2 edges\n",
            "Warning: Could not find node matching initial atoms: {(InCol1 robot0), (InRow0 robot0)}\n",
            "Episode graph has 3 nodes, 2 edges\n",
            "BFS collected states for 0 atom sets\n",
            "\n",
            "=== Episode 87/100 ===\n",
            "Planning graph with 4 nodes and 6 edges\n",
            "Starting BFS exploration from node 2: {(InCol1 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 2: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 2 → 3 (operator: MoveUp_from_row0)\n",
            "    → Reached target node 3 in 4 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 2 → 0 (operator: MoveLeft_from_col1)\n",
            "    → Reached target node 0 in 2 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 3: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 1, Visited nodes: 3\n",
            "\n",
            "[3] Exploring from node 0: frozenset({(InCol0 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 3\n",
            "  Trying edge 0 → 1 (operator: MoveUp_from_row0)\n",
            "    → Reached target node 1 in 4 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[4] Exploring from node 1: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 4\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 4/4 nodes\n",
            "Discovered 4 unique atom sets\n",
            "Total states collected: 4\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 6 edges\n",
            "BFS collected states for 4 atom sets\n",
            "\n",
            "=== Episode 88/100 ===\n",
            "Planning graph with 4 nodes and 4 edges\n",
            "Starting BFS exploration from node 3: {(InCol0 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 3: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/4 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 4 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 89/100 ===\n",
            "Planning graph with 4 nodes and 6 edges\n",
            "Starting BFS exploration from node 1: {(InRow1 robot0), (InCol0 robot0)}\n",
            "\n",
            "[1] Exploring from node 1: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 1 → 3 (operator: MoveDown_from_row1)\n",
            "    → Reached target node 3 in 2 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 1 → 0 (operator: MoveRight_from_col0)\n",
            "    → Reached target node 0 in 4 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 3: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 3\n",
            "\n",
            "[3] Exploring from node 0: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 0, Visited nodes: 3\n",
            "  Trying edge 0 → 2 (operator: MoveDown_from_row1)\n",
            "    → Reached target node 2 in 2 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[4] Exploring from node 2: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 4\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 4/4 nodes\n",
            "Discovered 4 unique atom sets\n",
            "Total states collected: 4\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 6 edges\n",
            "BFS collected states for 4 atom sets\n",
            "\n",
            "=== Episode 90/100 ===\n",
            "Planning graph with 4 nodes and 6 edges\n",
            "Starting BFS exploration from node 3: {(InCol0 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 3: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/4 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 6 edges\n",
            "BFS collected states for 1 atom sets\n",
            "  Episode 90/100: 4 nodes, 8 edges\n",
            "\n",
            "=== Episode 91/100 ===\n",
            "Planning graph with 4 nodes and 4 edges\n",
            "Starting BFS exploration from node 3: {(InCol0 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 3: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/4 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 4 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 92/100 ===\n",
            "Planning graph with 4 nodes and 4 edges\n",
            "Starting BFS exploration from node 2: {(InCol1 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 2: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/4 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 4 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 93/100 ===\n",
            "Planning graph with 1 nodes and 0 edges\n",
            "Starting BFS exploration from node 0: {(InCol1 robot0), (InRow1 robot0)}\n",
            "\n",
            "[1] Exploring from node 0: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/1 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 1 nodes, 0 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 94/100 ===\n",
            "Planning graph with 4 nodes and 6 edges\n",
            "Starting BFS exploration from node 3: {(InCol0 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 3: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/4 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 6 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 95/100 ===\n",
            "Planning graph with 3 nodes and 2 edges\n",
            "Warning: Could not find node matching initial atoms: {(InCol1 robot0), (InRow0 robot0)}\n",
            "Episode graph has 3 nodes, 2 edges\n",
            "BFS collected states for 0 atom sets\n",
            "  Episode 95/100: 4 nodes, 8 edges\n",
            "\n",
            "=== Episode 96/100 ===\n",
            "Planning graph with 3 nodes and 2 edges\n",
            "Starting BFS exploration from node 2: {(InCol0 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 2: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/3 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 3 nodes, 2 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 97/100 ===\n",
            "Planning graph with 4 nodes and 4 edges\n",
            "Starting BFS exploration from node 3: {(InCol0 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 3: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/4 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 4 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 98/100 ===\n",
            "Planning graph with 1 nodes and 0 edges\n",
            "Warning: Could not find node matching initial atoms: {(InCol1 robot0), (InRow1 robot0)}\n",
            "Episode graph has 1 nodes, 0 edges\n",
            "BFS collected states for 0 atom sets\n",
            "\n",
            "=== Episode 99/100 ===\n",
            "Planning graph with 4 nodes and 6 edges\n",
            "Starting BFS exploration from node 3: {(InCol0 robot0), (InRow0 robot0)}\n",
            "\n",
            "[1] Exploring from node 3: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 1/4 nodes\n",
            "Discovered 1 unique atom sets\n",
            "Total states collected: 1\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 6 edges\n",
            "BFS collected states for 1 atom sets\n",
            "\n",
            "=== Episode 100/100 ===\n",
            "Planning graph with 4 nodes and 6 edges\n",
            "Starting BFS exploration from node 1: {(InRow1 robot0), (InCol0 robot0)}\n",
            "\n",
            "[1] Exploring from node 1: frozenset({(InRow1 robot0), (InCol0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 1\n",
            "  Trying edge 1 → 3 (operator: MoveDown_from_row1)\n",
            "    → Reached target node 3 in 4 steps\n",
            "    ✓ Added to queue for exploration\n",
            "  Trying edge 1 → 0 (operator: MoveRight_from_col0)\n",
            "    → Reached target node 0 in 4 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[2] Exploring from node 3: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Queue size: 1, Visited nodes: 3\n",
            "\n",
            "[3] Exploring from node 0: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Queue size: 0, Visited nodes: 3\n",
            "  Trying edge 0 → 2 (operator: MoveDown_from_row1)\n",
            "    → Reached target node 2 in 4 steps\n",
            "    ✓ Added to queue for exploration\n",
            "\n",
            "[4] Exploring from node 2: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Queue size: 0, Visited nodes: 4\n",
            "\n",
            "================================================================================\n",
            "BFS Exploration Complete\n",
            "================================================================================\n",
            "Visited 4/4 nodes\n",
            "Discovered 4 unique atom sets\n",
            "Total states collected: 4\n",
            "\n",
            "Atom sets discovered:\n",
            "  • (InCol0 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol0 robot0), (InRow0 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow1 robot0) (1 states)\n",
            "  • (InCol1 robot0), (InRow0 robot0) (1 states)\n",
            "================================================================================\n",
            "\n",
            "Episode graph has 4 nodes, 6 edges\n",
            "BFS collected states for 4 atom sets\n",
            "  Episode 100/100: 4 nodes, 8 edges\n",
            "Total graph complete: 4 nodes, 8 edges, 69 total states\n",
            "\n",
            "Node ID -> Atoms mapping:\n",
            "================================================================================\n",
            "  Node   0 (15 states): (InCol1 robot0), (InRow0 robot0)\n",
            "  Node   1 (17 states): (InCol1 robot0), (InRow1 robot0)\n",
            "  Node   2 (19 states): (InCol0 robot0), (InRow0 robot0)\n",
            "  Node   3 (18 states): (InCol0 robot0), (InRow1 robot0)\n",
            "================================================================================\n",
            "\n",
            "Computing edge costs using 25 samples per edge...\n",
            "Edge cost computation complete!\n",
            "\n",
            "================================================================================\n",
            "Identifying shortcuts from total graph\n",
            "================================================================================\n",
            "Identified 2 shortcut candidates\n",
            "\n",
            "================================================================================\n",
            "Collection complete: 32 training examples, 32 shortcuts\n",
            "================================================================================\n",
            "\n",
            "✓ Collection complete!\n",
            "  Nodes with states: 4\n",
            "  Total shortcuts: 32\n",
            "  Planning graph: 4 nodes, 8 edges\n"
          ]
        }
      ],
      "source": [
        "# Collection config\n",
        "config_dict = {\n",
        "    \"seed\": 42,\n",
        "    \"collect_episodes\": 100,\n",
        "    \"use_random_rollouts\": True,\n",
        "    \"num_rollouts_per_node\": 5,\n",
        "    \"max_steps_per_rollout\": 100,\n",
        "    \"shortcut_success_threshold\": 0.5,\n",
        "}\n",
        "\n",
        "# Collect data\n",
        "print(\"\\nCollecting training data...\")\n",
        "rng = np.random.default_rng(42)\n",
        "training_data = collect_total_shortcuts(system, approach, config_dict, rng=rng)\n",
        "\n",
        "print(f\"\\n✓ Collection complete!\")\n",
        "print(f\"  Nodes with states: {len(training_data.node_states)}\")\n",
        "print(f\"  Total shortcuts: {len(training_data.valid_shortcuts)}\")\n",
        "print(f\"  Planning graph: {len(training_data.graph.nodes)} nodes, {len(training_data.graph.edges)} edges\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Prepare State-Node Pairs and Atom-to-Node Mapping\n",
        "\n",
        "V4 uses (state, node) pairs instead of (state, state) pairs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Created atoms_to_node mapping with 4 nodes\n",
            "\n",
            "Node mapping:\n",
            "  Node 0: frozenset({(InCol1 robot0), (InRow0 robot0)})\n",
            "  Node 1: frozenset({(InCol1 robot0), (InRow1 robot0)})\n",
            "  Node 2: frozenset({(InRow0 robot0), (InCol0 robot0)})\n",
            "  Node 3: frozenset({(InRow1 robot0), (InCol0 robot0)})\n"
          ]
        }
      ],
      "source": [
        "# Extract planning graph\n",
        "planning_graph = training_data.graph\n",
        "all_node_states = training_data.node_states\n",
        "\n",
        "# Create atoms_to_node mapping\n",
        "atoms_to_node = {}\n",
        "for node in planning_graph.nodes:\n",
        "    atoms_to_node[node.atoms] = node.id\n",
        "\n",
        "print(f\"✓ Created atoms_to_node mapping with {len(atoms_to_node)} nodes\")\n",
        "print(f\"\\nNode mapping:\")\n",
        "for node in planning_graph.nodes:\n",
        "    print(f\"  Node {node.id}: {node.atoms}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✓ Prepared 207 state-node pairs for training\n",
            "\n",
            "Sample state-node pairs:\n",
            "  Pair 0: 2 source atoms -> node 1 (2 atoms)\n",
            "  Pair 1: 2 source atoms -> node 1 (2 atoms)\n",
            "  Pair 2: 2 source atoms -> node 1 (2 atoms)\n"
          ]
        }
      ],
      "source": [
        "# Collect all (source_state, target_node) pairs\n",
        "state_node_pairs = []\n",
        "for source_node in planning_graph.nodes:\n",
        "    for target_node in planning_graph.nodes:\n",
        "        if source_node.id == target_node.id:\n",
        "            continue\n",
        "        \n",
        "        if source_node.id not in all_node_states:\n",
        "            continue\n",
        "        \n",
        "        source_states = all_node_states[source_node.id]\n",
        "        \n",
        "        if not source_states:\n",
        "            continue\n",
        "        \n",
        "        # For each source state, pair it with the target node ID\n",
        "        for source_state in source_states:\n",
        "            state_node_pairs.append((source_state, target_node.id))\n",
        "\n",
        "print(f\"\\n✓ Prepared {len(state_node_pairs)} state-node pairs for training\")\n",
        "\n",
        "# Sample a few pairs to inspect\n",
        "print(\"\\nSample state-node pairs:\")\n",
        "for i, (source_state, target_node) in enumerate(state_node_pairs[:3]):\n",
        "    source_atoms = system.perceiver.step(source_state)\n",
        "    target_atoms = planning_graph.nodes[target_node].atoms\n",
        "    print(f\"  Pair {i}: {len(source_atoms)} source atoms -> node {target_node} ({len(target_atoms)} atoms)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Train Distance Heuristic V4\n",
        "\n",
        "Train using contrastive state-node learning with normalized embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create distance heuristic config\n",
        "heuristic_config = DistanceHeuristicV4Config(\n",
        "    latent_dim=2,\n",
        "    hidden_dims=[64, 64],\n",
        "    learning_rate=1e-3,\n",
        "    batch_size=128,\n",
        "    buffer_size=10000,\n",
        "    gamma=0.9,\n",
        "    iters_per_epoch=1,\n",
        "    device=device,\n",
        "    repetition_factor=1,\n",
        "    policy_temperature=1,\n",
        "    learn_frequency=1\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting training...\n",
            "\n",
            "\n",
            "Training distance heuristic V4 on 207 state-node pairs...\n",
            "Device: cpu\n",
            "Number of nodes: 4\n",
            "State dimension: 2\n",
            "Latent dimension: 2\n",
            "\n",
            "Starting training for 300 epochs...\n",
            "Collecting 10 trajectories per epoch\n",
            "Using cosine annealing LR scheduler: 0.001 -> 1e-05\n",
            "\n",
            "[Epoch 12/300]\n",
            "  Buffer size: 130\n",
            "  Learning rate: 0.000996\n",
            "  Policy temperature: 0.9954\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 70.00% (7/10)\n",
            "  Avg trajectory length: 69.1\n",
            "  Avg successful length: 55.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.9019\n",
            "  Alignment loss: 0.2525\n",
            "  Uniformity loss: 4.6495\n",
            "  Accuracy: 19.53%\n",
            "\n",
            "[Epoch 13/300]\n",
            "  Buffer size: 140\n",
            "  Learning rate: 0.000995\n",
            "  Policy temperature: 0.9946\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 80.00% (8/10)\n",
            "  Avg trajectory length: 64.6\n",
            "  Avg successful length: 55.5\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.8792\n",
            "  Alignment loss: 0.1708\n",
            "  Uniformity loss: 4.7084\n",
            "  Accuracy: 38.28%\n",
            "\n",
            "[Epoch 14/300]\n",
            "  Buffer size: 150\n",
            "  Learning rate: 0.000995\n",
            "  Policy temperature: 0.9938\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 60.00% (6/10)\n",
            "  Avg trajectory length: 77.1\n",
            "  Avg successful length: 61.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.8518\n",
            "  Alignment loss: 0.1299\n",
            "  Uniformity loss: 4.7220\n",
            "  Accuracy: 14.84%\n",
            "\n",
            "[Epoch 15/300]\n",
            "  Buffer size: 160\n",
            "  Learning rate: 0.000994\n",
            "  Policy temperature: 0.9930\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 48.9\n",
            "  Avg successful length: 43.1\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.8277\n",
            "  Alignment loss: 0.1036\n",
            "  Uniformity loss: 4.7241\n",
            "  Accuracy: 18.75%\n",
            "\n",
            "[Epoch 16/300]\n",
            "  Buffer size: 170\n",
            "  Learning rate: 0.000993\n",
            "  Policy temperature: 0.9921\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 50.00% (5/10)\n",
            "  Avg trajectory length: 73.6\n",
            "  Avg successful length: 46.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.8219\n",
            "  Alignment loss: 0.1316\n",
            "  Uniformity loss: 4.6904\n",
            "  Accuracy: 22.66%\n",
            "\n",
            "[Epoch 17/300]\n",
            "  Buffer size: 180\n",
            "  Learning rate: 0.000992\n",
            "  Policy temperature: 0.9911\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 60.00% (6/10)\n",
            "  Avg trajectory length: 58.5\n",
            "  Avg successful length: 30.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.8157\n",
            "  Alignment loss: 0.1455\n",
            "  Uniformity loss: 4.6702\n",
            "  Accuracy: 25.00%\n",
            "\n",
            "[Epoch 18/300]\n",
            "  Buffer size: 190\n",
            "  Learning rate: 0.000991\n",
            "  Policy temperature: 0.9901\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 40.00% (4/10)\n",
            "  Avg trajectory length: 62.6\n",
            "  Avg successful length: 5.0\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.8145\n",
            "  Alignment loss: 0.2026\n",
            "  Uniformity loss: 4.6120\n",
            "  Accuracy: 21.88%\n",
            "\n",
            "[Epoch 19/300]\n",
            "  Buffer size: 200\n",
            "  Learning rate: 0.000990\n",
            "  Policy temperature: 0.9891\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 50.00% (5/10)\n",
            "  Avg trajectory length: 72.1\n",
            "  Avg successful length: 43.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.8066\n",
            "  Alignment loss: 0.2544\n",
            "  Uniformity loss: 4.5521\n",
            "  Accuracy: 38.28%\n",
            "\n",
            "[Epoch 20/300]\n",
            "  Buffer size: 210\n",
            "  Learning rate: 0.000989\n",
            "  Policy temperature: 0.9880\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 70.00% (7/10)\n",
            "  Avg trajectory length: 59.3\n",
            "  Avg successful length: 41.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.7777\n",
            "  Alignment loss: 0.2841\n",
            "  Uniformity loss: 4.4935\n",
            "  Accuracy: 39.84%\n",
            "\n",
            "[Epoch 21/300]\n",
            "  Buffer size: 220\n",
            "  Learning rate: 0.000988\n",
            "  Policy temperature: 0.9868\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 40.2\n",
            "  Avg successful length: 33.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.7238\n",
            "  Alignment loss: 0.2718\n",
            "  Uniformity loss: 4.4520\n",
            "  Accuracy: 50.00%\n",
            "\n",
            "[Epoch 22/300]\n",
            "  Buffer size: 230\n",
            "  Learning rate: 0.000987\n",
            "  Policy temperature: 0.9856\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 32.3\n",
            "  Avg successful length: 24.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.7313\n",
            "  Alignment loss: 0.3251\n",
            "  Uniformity loss: 4.4062\n",
            "  Accuracy: 43.75%\n",
            "\n",
            "[Epoch 23/300]\n",
            "  Buffer size: 240\n",
            "  Learning rate: 0.000986\n",
            "  Policy temperature: 0.9843\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 60.00% (6/10)\n",
            "  Avg trajectory length: 52.6\n",
            "  Avg successful length: 20.3\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.7406\n",
            "  Alignment loss: 0.4147\n",
            "  Uniformity loss: 4.3258\n",
            "  Accuracy: 47.66%\n",
            "\n",
            "[Epoch 24/300]\n",
            "  Buffer size: 250\n",
            "  Learning rate: 0.000984\n",
            "  Policy temperature: 0.9830\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 59.1\n",
            "  Avg successful length: 54.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.7099\n",
            "  Alignment loss: 0.4538\n",
            "  Uniformity loss: 4.2561\n",
            "  Accuracy: 41.41%\n",
            "\n",
            "[Epoch 25/300]\n",
            "  Buffer size: 260\n",
            "  Learning rate: 0.000983\n",
            "  Policy temperature: 0.9816\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 27.8\n",
            "  Avg successful length: 19.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6076\n",
            "  Alignment loss: 0.3231\n",
            "  Uniformity loss: 4.2846\n",
            "  Accuracy: 58.59%\n",
            "\n",
            "[Epoch 26/300]\n",
            "  Buffer size: 270\n",
            "  Learning rate: 0.000982\n",
            "  Policy temperature: 0.9801\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 80.00% (8/10)\n",
            "  Avg trajectory length: 59.0\n",
            "  Avg successful length: 48.5\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.7379\n",
            "  Alignment loss: 0.5128\n",
            "  Uniformity loss: 4.2251\n",
            "  Accuracy: 44.53%\n",
            "\n",
            "[Epoch 27/300]\n",
            "  Buffer size: 280\n",
            "  Learning rate: 0.000980\n",
            "  Policy temperature: 0.9787\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 60.00% (6/10)\n",
            "  Avg trajectory length: 63.2\n",
            "  Avg successful length: 38.0\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6615\n",
            "  Alignment loss: 0.4741\n",
            "  Uniformity loss: 4.1873\n",
            "  Accuracy: 53.91%\n",
            "\n",
            "[Epoch 28/300]\n",
            "  Buffer size: 290\n",
            "  Learning rate: 0.000979\n",
            "  Policy temperature: 0.9771\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 40.00% (4/10)\n",
            "  Avg trajectory length: 68.3\n",
            "  Avg successful length: 19.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.7319\n",
            "  Alignment loss: 0.5932\n",
            "  Uniformity loss: 4.1387\n",
            "  Accuracy: 48.44%\n",
            "\n",
            "[Epoch 29/300]\n",
            "  Buffer size: 300\n",
            "  Learning rate: 0.000977\n",
            "  Policy temperature: 0.9755\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 80.00% (8/10)\n",
            "  Avg trajectory length: 42.1\n",
            "  Avg successful length: 27.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5533\n",
            "  Alignment loss: 0.3820\n",
            "  Uniformity loss: 4.1713\n",
            "  Accuracy: 60.16%\n",
            "\n",
            "[Epoch 30/300]\n",
            "  Buffer size: 310\n",
            "  Learning rate: 0.000976\n",
            "  Policy temperature: 0.9739\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 60.00% (6/10)\n",
            "  Avg trajectory length: 46.6\n",
            "  Avg successful length: 10.3\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6170\n",
            "  Alignment loss: 0.4736\n",
            "  Uniformity loss: 4.1434\n",
            "  Accuracy: 53.91%\n",
            "\n",
            "[Epoch 31/300]\n",
            "  Buffer size: 320\n",
            "  Learning rate: 0.000974\n",
            "  Policy temperature: 0.9722\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 37.7\n",
            "  Avg successful length: 30.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5635\n",
            "  Alignment loss: 0.4221\n",
            "  Uniformity loss: 4.1414\n",
            "  Accuracy: 58.59%\n",
            "\n",
            "[Epoch 32/300]\n",
            "  Buffer size: 330\n",
            "  Learning rate: 0.000972\n",
            "  Policy temperature: 0.9704\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 70.00% (7/10)\n",
            "  Avg trajectory length: 56.5\n",
            "  Avg successful length: 37.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5559\n",
            "  Alignment loss: 0.4780\n",
            "  Uniformity loss: 4.0778\n",
            "  Accuracy: 57.81%\n",
            "\n",
            "[Epoch 33/300]\n",
            "  Buffer size: 340\n",
            "  Learning rate: 0.000971\n",
            "  Policy temperature: 0.9686\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 80.00% (8/10)\n",
            "  Avg trajectory length: 56.5\n",
            "  Avg successful length: 45.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5988\n",
            "  Alignment loss: 0.5753\n",
            "  Uniformity loss: 4.0234\n",
            "  Accuracy: 50.78%\n",
            "\n",
            "[Epoch 34/300]\n",
            "  Buffer size: 350\n",
            "  Learning rate: 0.000969\n",
            "  Policy temperature: 0.9668\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 80.00% (8/10)\n",
            "  Avg trajectory length: 49.1\n",
            "  Avg successful length: 36.1\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6088\n",
            "  Alignment loss: 0.6199\n",
            "  Uniformity loss: 3.9889\n",
            "  Accuracy: 49.22%\n",
            "\n",
            "[Epoch 35/300]\n",
            "  Buffer size: 360\n",
            "  Learning rate: 0.000967\n",
            "  Policy temperature: 0.9649\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 80.00% (8/10)\n",
            "  Avg trajectory length: 51.1\n",
            "  Avg successful length: 38.6\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5498\n",
            "  Alignment loss: 0.5168\n",
            "  Uniformity loss: 4.0331\n",
            "  Accuracy: 56.25%\n",
            "\n",
            "[Epoch 36/300]\n",
            "  Buffer size: 370\n",
            "  Learning rate: 0.000965\n",
            "  Policy temperature: 0.9629\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 34.8\n",
            "  Avg successful length: 27.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5974\n",
            "  Alignment loss: 0.5631\n",
            "  Uniformity loss: 4.0344\n",
            "  Accuracy: 56.25%\n",
            "\n",
            "[Epoch 37/300]\n",
            "  Buffer size: 380\n",
            "  Learning rate: 0.000963\n",
            "  Policy temperature: 0.9609\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 56.6\n",
            "  Avg successful length: 51.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5596\n",
            "  Alignment loss: 0.5239\n",
            "  Uniformity loss: 4.0357\n",
            "  Accuracy: 56.25%\n",
            "\n",
            "[Epoch 38/300]\n",
            "  Buffer size: 390\n",
            "  Learning rate: 0.000961\n",
            "  Policy temperature: 0.9589\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 40.6\n",
            "  Avg successful length: 33.9\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5929\n",
            "  Alignment loss: 0.5218\n",
            "  Uniformity loss: 4.0711\n",
            "  Accuracy: 50.00%\n",
            "\n",
            "[Epoch 39/300]\n",
            "  Buffer size: 400\n",
            "  Learning rate: 0.000959\n",
            "  Policy temperature: 0.9568\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 37.7\n",
            "  Avg successful length: 30.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5267\n",
            "  Alignment loss: 0.4492\n",
            "  Uniformity loss: 4.0775\n",
            "  Accuracy: 54.69%\n",
            "\n",
            "[Epoch 40/300]\n",
            "  Buffer size: 410\n",
            "  Learning rate: 0.000957\n",
            "  Policy temperature: 0.9546\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 80.00% (8/10)\n",
            "  Avg trajectory length: 54.9\n",
            "  Avg successful length: 43.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5205\n",
            "  Alignment loss: 0.4105\n",
            "  Uniformity loss: 4.1100\n",
            "  Accuracy: 56.25%\n",
            "\n",
            "[Epoch 41/300]\n",
            "  Buffer size: 420\n",
            "  Learning rate: 0.000955\n",
            "  Policy temperature: 0.9524\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 19.7\n",
            "  Avg successful length: 19.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5760\n",
            "  Alignment loss: 0.4766\n",
            "  Uniformity loss: 4.0995\n",
            "  Accuracy: 57.03%\n",
            "\n",
            "[Epoch 42/300]\n",
            "  Buffer size: 430\n",
            "  Learning rate: 0.000953\n",
            "  Policy temperature: 0.9502\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 22.5\n",
            "  Avg successful length: 22.5\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5275\n",
            "  Alignment loss: 0.4489\n",
            "  Uniformity loss: 4.0786\n",
            "  Accuracy: 51.56%\n",
            "\n",
            "[Epoch 43/300]\n",
            "  Buffer size: 440\n",
            "  Learning rate: 0.000951\n",
            "  Policy temperature: 0.9479\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 26.4\n",
            "  Avg successful length: 26.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4769\n",
            "  Alignment loss: 0.4074\n",
            "  Uniformity loss: 4.0695\n",
            "  Accuracy: 56.25%\n",
            "\n",
            "[Epoch 44/300]\n",
            "  Buffer size: 450\n",
            "  Learning rate: 0.000948\n",
            "  Policy temperature: 0.9455\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 24.4\n",
            "  Avg successful length: 24.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5751\n",
            "  Alignment loss: 0.4766\n",
            "  Uniformity loss: 4.0986\n",
            "  Accuracy: 50.00%\n",
            "\n",
            "[Epoch 45/300]\n",
            "  Buffer size: 460\n",
            "  Learning rate: 0.000946\n",
            "  Policy temperature: 0.9431\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 25.7\n",
            "  Avg successful length: 25.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4957\n",
            "  Alignment loss: 0.4046\n",
            "  Uniformity loss: 4.0912\n",
            "  Accuracy: 60.16%\n",
            "\n",
            "[Epoch 46/300]\n",
            "  Buffer size: 470\n",
            "  Learning rate: 0.000944\n",
            "  Policy temperature: 0.9407\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 80.00% (8/10)\n",
            "  Avg trajectory length: 44.3\n",
            "  Avg successful length: 30.1\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5022\n",
            "  Alignment loss: 0.4035\n",
            "  Uniformity loss: 4.0987\n",
            "  Accuracy: 58.59%\n",
            "\n",
            "[Epoch 47/300]\n",
            "  Buffer size: 480\n",
            "  Learning rate: 0.000941\n",
            "  Policy temperature: 0.9382\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 80.00% (8/10)\n",
            "  Avg trajectory length: 42.3\n",
            "  Avg successful length: 27.6\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5828\n",
            "  Alignment loss: 0.5054\n",
            "  Uniformity loss: 4.0774\n",
            "  Accuracy: 52.34%\n",
            "\n",
            "[Epoch 48/300]\n",
            "  Buffer size: 490\n",
            "  Learning rate: 0.000939\n",
            "  Policy temperature: 0.9356\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 80.00% (8/10)\n",
            "  Avg trajectory length: 47.6\n",
            "  Avg successful length: 34.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5120\n",
            "  Alignment loss: 0.4203\n",
            "  Uniformity loss: 4.0917\n",
            "  Accuracy: 57.03%\n",
            "\n",
            "[Epoch 49/300]\n",
            "  Buffer size: 500\n",
            "  Learning rate: 0.000936\n",
            "  Policy temperature: 0.9330\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 43.0\n",
            "  Avg successful length: 36.6\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5296\n",
            "  Alignment loss: 0.4476\n",
            "  Uniformity loss: 4.0820\n",
            "  Accuracy: 53.12%\n",
            "\n",
            "[Epoch 50/300]\n",
            "  Buffer size: 510\n",
            "  Learning rate: 0.000934\n",
            "  Policy temperature: 0.9304\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 80.00% (8/10)\n",
            "  Avg trajectory length: 40.1\n",
            "  Avg successful length: 24.9\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5782\n",
            "  Alignment loss: 0.4805\n",
            "  Uniformity loss: 4.0977\n",
            "  Accuracy: 49.22%\n",
            "\n",
            "[Epoch 51/300]\n",
            "  Buffer size: 520\n",
            "  Learning rate: 0.000931\n",
            "  Policy temperature: 0.9277\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 23.6\n",
            "  Avg successful length: 23.6\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5283\n",
            "  Alignment loss: 0.4324\n",
            "  Uniformity loss: 4.0959\n",
            "  Accuracy: 53.91%\n",
            "\n",
            "[Epoch 52/300]\n",
            "  Buffer size: 530\n",
            "  Learning rate: 0.000928\n",
            "  Policy temperature: 0.9249\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 43.8\n",
            "  Avg successful length: 37.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5501\n",
            "  Alignment loss: 0.4590\n",
            "  Uniformity loss: 4.0911\n",
            "  Accuracy: 53.12%\n",
            "\n",
            "[Epoch 53/300]\n",
            "  Buffer size: 540\n",
            "  Learning rate: 0.000926\n",
            "  Policy temperature: 0.9222\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 41.3\n",
            "  Avg successful length: 34.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4797\n",
            "  Alignment loss: 0.4090\n",
            "  Uniformity loss: 4.0707\n",
            "  Accuracy: 57.81%\n",
            "\n",
            "[Epoch 54/300]\n",
            "  Buffer size: 550\n",
            "  Learning rate: 0.000923\n",
            "  Policy temperature: 0.9193\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 37.6\n",
            "  Avg successful length: 37.6\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5494\n",
            "  Alignment loss: 0.4681\n",
            "  Uniformity loss: 4.0813\n",
            "  Accuracy: 47.66%\n",
            "\n",
            "[Epoch 55/300]\n",
            "  Buffer size: 560\n",
            "  Learning rate: 0.000920\n",
            "  Policy temperature: 0.9165\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 80.00% (8/10)\n",
            "  Avg trajectory length: 35.6\n",
            "  Avg successful length: 19.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4983\n",
            "  Alignment loss: 0.4069\n",
            "  Uniformity loss: 4.0915\n",
            "  Accuracy: 58.59%\n",
            "\n",
            "[Epoch 56/300]\n",
            "  Buffer size: 570\n",
            "  Learning rate: 0.000917\n",
            "  Policy temperature: 0.9135\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 40.9\n",
            "  Avg successful length: 34.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5157\n",
            "  Alignment loss: 0.4154\n",
            "  Uniformity loss: 4.1002\n",
            "  Accuracy: 57.03%\n",
            "\n",
            "[Epoch 57/300]\n",
            "  Buffer size: 580\n",
            "  Learning rate: 0.000914\n",
            "  Policy temperature: 0.9106\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 47.5\n",
            "  Avg successful length: 41.6\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5827\n",
            "  Alignment loss: 0.4923\n",
            "  Uniformity loss: 4.0904\n",
            "  Accuracy: 46.09%\n",
            "\n",
            "[Epoch 58/300]\n",
            "  Buffer size: 590\n",
            "  Learning rate: 0.000911\n",
            "  Policy temperature: 0.9076\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 80.00% (8/10)\n",
            "  Avg trajectory length: 44.5\n",
            "  Avg successful length: 30.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4943\n",
            "  Alignment loss: 0.3972\n",
            "  Uniformity loss: 4.0971\n",
            "  Accuracy: 60.16%\n",
            "\n",
            "[Epoch 59/300]\n",
            "  Buffer size: 600\n",
            "  Learning rate: 0.000908\n",
            "  Policy temperature: 0.9045\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 38.7\n",
            "  Avg successful length: 31.8\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6067\n",
            "  Alignment loss: 0.5102\n",
            "  Uniformity loss: 4.0965\n",
            "  Accuracy: 45.31%\n",
            "\n",
            "[Epoch 60/300]\n",
            "  Buffer size: 610\n",
            "  Learning rate: 0.000905\n",
            "  Policy temperature: 0.9014\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 18.7\n",
            "  Avg successful length: 18.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5552\n",
            "  Alignment loss: 0.4389\n",
            "  Uniformity loss: 4.1163\n",
            "  Accuracy: 53.91%\n",
            "\n",
            "[Epoch 61/300]\n",
            "  Buffer size: 620\n",
            "  Learning rate: 0.000902\n",
            "  Policy temperature: 0.8983\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 25.7\n",
            "  Avg successful length: 25.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5138\n",
            "  Alignment loss: 0.3920\n",
            "  Uniformity loss: 4.1218\n",
            "  Accuracy: 59.38%\n",
            "\n",
            "[Epoch 62/300]\n",
            "  Buffer size: 630\n",
            "  Learning rate: 0.000899\n",
            "  Policy temperature: 0.8951\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 39.4\n",
            "  Avg successful length: 32.6\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5248\n",
            "  Alignment loss: 0.4309\n",
            "  Uniformity loss: 4.0939\n",
            "  Accuracy: 50.78%\n",
            "\n",
            "[Epoch 63/300]\n",
            "  Buffer size: 640\n",
            "  Learning rate: 0.000896\n",
            "  Policy temperature: 0.8918\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 34.8\n",
            "  Avg successful length: 27.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5781\n",
            "  Alignment loss: 0.4831\n",
            "  Uniformity loss: 4.0950\n",
            "  Accuracy: 57.03%\n",
            "\n",
            "[Epoch 64/300]\n",
            "  Buffer size: 650\n",
            "  Learning rate: 0.000893\n",
            "  Policy temperature: 0.8886\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 80.00% (8/10)\n",
            "  Avg trajectory length: 25.0\n",
            "  Avg successful length: 6.0\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5158\n",
            "  Alignment loss: 0.4165\n",
            "  Uniformity loss: 4.0992\n",
            "  Accuracy: 49.22%\n",
            "\n",
            "[Epoch 65/300]\n",
            "  Buffer size: 660\n",
            "  Learning rate: 0.000890\n",
            "  Policy temperature: 0.8853\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 39.5\n",
            "  Avg successful length: 39.5\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4901\n",
            "  Alignment loss: 0.3787\n",
            "  Uniformity loss: 4.1114\n",
            "  Accuracy: 63.28%\n",
            "\n",
            "[Epoch 66/300]\n",
            "  Buffer size: 670\n",
            "  Learning rate: 0.000886\n",
            "  Policy temperature: 0.8819\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 39.3\n",
            "  Avg successful length: 32.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4863\n",
            "  Alignment loss: 0.3916\n",
            "  Uniformity loss: 4.0946\n",
            "  Accuracy: 57.03%\n",
            "\n",
            "[Epoch 67/300]\n",
            "  Buffer size: 680\n",
            "  Learning rate: 0.000883\n",
            "  Policy temperature: 0.8785\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 80.00% (8/10)\n",
            "  Avg trajectory length: 42.3\n",
            "  Avg successful length: 27.6\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4845\n",
            "  Alignment loss: 0.3925\n",
            "  Uniformity loss: 4.0920\n",
            "  Accuracy: 56.25%\n",
            "\n",
            "[Epoch 68/300]\n",
            "  Buffer size: 690\n",
            "  Learning rate: 0.000880\n",
            "  Policy temperature: 0.8751\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 43.6\n",
            "  Avg successful length: 37.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5444\n",
            "  Alignment loss: 0.4832\n",
            "  Uniformity loss: 4.0611\n",
            "  Accuracy: 57.03%\n",
            "\n",
            "[Epoch 69/300]\n",
            "  Buffer size: 700\n",
            "  Learning rate: 0.000876\n",
            "  Policy temperature: 0.8716\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 35.5\n",
            "  Avg successful length: 28.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6539\n",
            "  Alignment loss: 0.6098\n",
            "  Uniformity loss: 4.0442\n",
            "  Accuracy: 49.22%\n",
            "\n",
            "[Epoch 70/300]\n",
            "  Buffer size: 710\n",
            "  Learning rate: 0.000873\n",
            "  Policy temperature: 0.8680\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 35.0\n",
            "  Avg successful length: 27.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5157\n",
            "  Alignment loss: 0.4162\n",
            "  Uniformity loss: 4.0995\n",
            "  Accuracy: 62.50%\n",
            "\n",
            "[Epoch 71/300]\n",
            "  Buffer size: 720\n",
            "  Learning rate: 0.000869\n",
            "  Policy temperature: 0.8645\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 32.8\n",
            "  Avg successful length: 25.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5577\n",
            "  Alignment loss: 0.4682\n",
            "  Uniformity loss: 4.0895\n",
            "  Accuracy: 53.91%\n",
            "\n",
            "[Epoch 72/300]\n",
            "  Buffer size: 730\n",
            "  Learning rate: 0.000866\n",
            "  Policy temperature: 0.8609\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 33.8\n",
            "  Avg successful length: 26.3\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5390\n",
            "  Alignment loss: 0.4282\n",
            "  Uniformity loss: 4.1108\n",
            "  Accuracy: 57.03%\n",
            "\n",
            "[Epoch 73/300]\n",
            "  Buffer size: 740\n",
            "  Learning rate: 0.000862\n",
            "  Policy temperature: 0.8572\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 70.00% (7/10)\n",
            "  Avg trajectory length: 56.0\n",
            "  Avg successful length: 36.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5031\n",
            "  Alignment loss: 0.3851\n",
            "  Uniformity loss: 4.1180\n",
            "  Accuracy: 61.72%\n",
            "\n",
            "[Epoch 74/300]\n",
            "  Buffer size: 750\n",
            "  Learning rate: 0.000859\n",
            "  Policy temperature: 0.8536\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 29.1\n",
            "  Avg successful length: 29.1\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6618\n",
            "  Alignment loss: 0.5538\n",
            "  Uniformity loss: 4.1080\n",
            "  Accuracy: 47.66%\n",
            "\n",
            "[Epoch 75/300]\n",
            "  Buffer size: 760\n",
            "  Learning rate: 0.000855\n",
            "  Policy temperature: 0.8498\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 27.9\n",
            "  Avg successful length: 27.9\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5207\n",
            "  Alignment loss: 0.4358\n",
            "  Uniformity loss: 4.0849\n",
            "  Accuracy: 56.25%\n",
            "\n",
            "[Epoch 76/300]\n",
            "  Buffer size: 770\n",
            "  Learning rate: 0.000851\n",
            "  Policy temperature: 0.8461\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 80.00% (8/10)\n",
            "  Avg trajectory length: 43.4\n",
            "  Avg successful length: 29.0\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4313\n",
            "  Alignment loss: 0.3224\n",
            "  Uniformity loss: 4.1089\n",
            "  Accuracy: 67.97%\n",
            "\n",
            "[Epoch 77/300]\n",
            "  Buffer size: 780\n",
            "  Learning rate: 0.000848\n",
            "  Policy temperature: 0.8423\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 31.4\n",
            "  Avg successful length: 31.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5937\n",
            "  Alignment loss: 0.5118\n",
            "  Uniformity loss: 4.0820\n",
            "  Accuracy: 50.78%\n",
            "\n",
            "[Epoch 78/300]\n",
            "  Buffer size: 790\n",
            "  Learning rate: 0.000844\n",
            "  Policy temperature: 0.8384\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 30.9\n",
            "  Avg successful length: 30.9\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5160\n",
            "  Alignment loss: 0.4273\n",
            "  Uniformity loss: 4.0888\n",
            "  Accuracy: 53.91%\n",
            "\n",
            "[Epoch 79/300]\n",
            "  Buffer size: 800\n",
            "  Learning rate: 0.000840\n",
            "  Policy temperature: 0.8346\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 36.2\n",
            "  Avg successful length: 29.0\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4658\n",
            "  Alignment loss: 0.3610\n",
            "  Uniformity loss: 4.1048\n",
            "  Accuracy: 53.12%\n",
            "\n",
            "[Epoch 80/300]\n",
            "  Buffer size: 810\n",
            "  Learning rate: 0.000836\n",
            "  Policy temperature: 0.8307\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 30.7\n",
            "  Avg successful length: 22.9\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5042\n",
            "  Alignment loss: 0.4075\n",
            "  Uniformity loss: 4.0968\n",
            "  Accuracy: 51.56%\n",
            "\n",
            "[Epoch 81/300]\n",
            "  Buffer size: 820\n",
            "  Learning rate: 0.000832\n",
            "  Policy temperature: 0.8267\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 20.6\n",
            "  Avg successful length: 20.6\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5561\n",
            "  Alignment loss: 0.4554\n",
            "  Uniformity loss: 4.1007\n",
            "  Accuracy: 54.69%\n",
            "\n",
            "[Epoch 82/300]\n",
            "  Buffer size: 830\n",
            "  Learning rate: 0.000828\n",
            "  Policy temperature: 0.8227\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 14.8\n",
            "  Avg successful length: 14.8\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4767\n",
            "  Alignment loss: 0.3720\n",
            "  Uniformity loss: 4.1047\n",
            "  Accuracy: 56.25%\n",
            "\n",
            "[Epoch 83/300]\n",
            "  Buffer size: 840\n",
            "  Learning rate: 0.000825\n",
            "  Policy temperature: 0.8187\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 34.3\n",
            "  Avg successful length: 26.9\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5114\n",
            "  Alignment loss: 0.3981\n",
            "  Uniformity loss: 4.1134\n",
            "  Accuracy: 58.59%\n",
            "\n",
            "[Epoch 84/300]\n",
            "  Buffer size: 850\n",
            "  Learning rate: 0.000821\n",
            "  Policy temperature: 0.8147\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 80.00% (8/10)\n",
            "  Avg trajectory length: 42.6\n",
            "  Avg successful length: 28.0\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4852\n",
            "  Alignment loss: 0.3967\n",
            "  Uniformity loss: 4.0885\n",
            "  Accuracy: 59.38%\n",
            "\n",
            "[Epoch 85/300]\n",
            "  Buffer size: 860\n",
            "  Learning rate: 0.000817\n",
            "  Policy temperature: 0.8106\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 48.2\n",
            "  Avg successful length: 42.3\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6065\n",
            "  Alignment loss: 0.5178\n",
            "  Uniformity loss: 4.0886\n",
            "  Accuracy: 50.78%\n",
            "\n",
            "[Epoch 86/300]\n",
            "  Buffer size: 870\n",
            "  Learning rate: 0.000812\n",
            "  Policy temperature: 0.8065\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 22.7\n",
            "  Avg successful length: 22.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5504\n",
            "  Alignment loss: 0.4614\n",
            "  Uniformity loss: 4.0890\n",
            "  Accuracy: 52.34%\n",
            "\n",
            "[Epoch 87/300]\n",
            "  Buffer size: 880\n",
            "  Learning rate: 0.000808\n",
            "  Policy temperature: 0.8023\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 30.0\n",
            "  Avg successful length: 22.1\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5422\n",
            "  Alignment loss: 0.4843\n",
            "  Uniformity loss: 4.0579\n",
            "  Accuracy: 51.56%\n",
            "\n",
            "[Epoch 88/300]\n",
            "  Buffer size: 890\n",
            "  Learning rate: 0.000804\n",
            "  Policy temperature: 0.7981\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 30.4\n",
            "  Avg successful length: 22.6\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5737\n",
            "  Alignment loss: 0.4635\n",
            "  Uniformity loss: 4.1102\n",
            "  Accuracy: 52.34%\n",
            "\n",
            "[Epoch 89/300]\n",
            "  Buffer size: 900\n",
            "  Learning rate: 0.000800\n",
            "  Policy temperature: 0.7939\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 38.7\n",
            "  Avg successful length: 38.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4998\n",
            "  Alignment loss: 0.4139\n",
            "  Uniformity loss: 4.0860\n",
            "  Accuracy: 54.69%\n",
            "\n",
            "[Epoch 90/300]\n",
            "  Buffer size: 910\n",
            "  Learning rate: 0.000796\n",
            "  Policy temperature: 0.7896\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 44.8\n",
            "  Avg successful length: 38.6\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4579\n",
            "  Alignment loss: 0.3721\n",
            "  Uniformity loss: 4.0857\n",
            "  Accuracy: 57.81%\n",
            "\n",
            "[Epoch 91/300]\n",
            "  Buffer size: 920\n",
            "  Learning rate: 0.000792\n",
            "  Policy temperature: 0.7854\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 26.1\n",
            "  Avg successful length: 26.1\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5144\n",
            "  Alignment loss: 0.4234\n",
            "  Uniformity loss: 4.0910\n",
            "  Accuracy: 56.25%\n",
            "\n",
            "[Epoch 92/300]\n",
            "  Buffer size: 930\n",
            "  Learning rate: 0.000788\n",
            "  Policy temperature: 0.7810\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 37.9\n",
            "  Avg successful length: 30.9\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5122\n",
            "  Alignment loss: 0.4017\n",
            "  Uniformity loss: 4.1105\n",
            "  Accuracy: 56.25%\n",
            "\n",
            "[Epoch 93/300]\n",
            "  Buffer size: 940\n",
            "  Learning rate: 0.000783\n",
            "  Policy temperature: 0.7767\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 23.5\n",
            "  Avg successful length: 14.9\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4813\n",
            "  Alignment loss: 0.3986\n",
            "  Uniformity loss: 4.0827\n",
            "  Accuracy: 56.25%\n",
            "\n",
            "[Epoch 94/300]\n",
            "  Buffer size: 950\n",
            "  Learning rate: 0.000779\n",
            "  Policy temperature: 0.7723\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 34.5\n",
            "  Avg successful length: 34.5\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5009\n",
            "  Alignment loss: 0.3843\n",
            "  Uniformity loss: 4.1166\n",
            "  Accuracy: 58.59%\n",
            "\n",
            "[Epoch 95/300]\n",
            "  Buffer size: 960\n",
            "  Learning rate: 0.000775\n",
            "  Policy temperature: 0.7679\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 30.8\n",
            "  Avg successful length: 23.0\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4879\n",
            "  Alignment loss: 0.3937\n",
            "  Uniformity loss: 4.0943\n",
            "  Accuracy: 53.91%\n",
            "\n",
            "[Epoch 96/300]\n",
            "  Buffer size: 970\n",
            "  Learning rate: 0.000770\n",
            "  Policy temperature: 0.7635\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 20.7\n",
            "  Avg successful length: 20.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5098\n",
            "  Alignment loss: 0.4063\n",
            "  Uniformity loss: 4.1035\n",
            "  Accuracy: 51.56%\n",
            "\n",
            "[Epoch 97/300]\n",
            "  Buffer size: 980\n",
            "  Learning rate: 0.000766\n",
            "  Policy temperature: 0.7590\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 43.5\n",
            "  Avg successful length: 37.1\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4951\n",
            "  Alignment loss: 0.4042\n",
            "  Uniformity loss: 4.0909\n",
            "  Accuracy: 56.25%\n",
            "\n",
            "[Epoch 98/300]\n",
            "  Buffer size: 990\n",
            "  Learning rate: 0.000761\n",
            "  Policy temperature: 0.7545\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 16.5\n",
            "  Avg successful length: 16.5\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4721\n",
            "  Alignment loss: 0.3721\n",
            "  Uniformity loss: 4.1000\n",
            "  Accuracy: 55.47%\n",
            "\n",
            "[Epoch 99/300]\n",
            "  Buffer size: 1000\n",
            "  Learning rate: 0.000757\n",
            "  Policy temperature: 0.7500\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 28.7\n",
            "  Avg successful length: 28.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4797\n",
            "  Alignment loss: 0.3784\n",
            "  Uniformity loss: 4.1013\n",
            "  Accuracy: 52.34%\n",
            "\n",
            "[Epoch 100/300]\n",
            "  Buffer size: 1010\n",
            "  Learning rate: 0.000752\n",
            "  Policy temperature: 0.7455\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 26.6\n",
            "  Avg successful length: 26.6\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4967\n",
            "  Alignment loss: 0.4047\n",
            "  Uniformity loss: 4.0920\n",
            "  Accuracy: 57.03%\n",
            "\n",
            "[Epoch 101/300]\n",
            "  Buffer size: 1020\n",
            "  Learning rate: 0.000748\n",
            "  Policy temperature: 0.7409\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 48.9\n",
            "  Avg successful length: 43.1\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5673\n",
            "  Alignment loss: 0.4722\n",
            "  Uniformity loss: 4.0951\n",
            "  Accuracy: 56.25%\n",
            "\n",
            "[Epoch 102/300]\n",
            "  Buffer size: 1030\n",
            "  Learning rate: 0.000743\n",
            "  Policy temperature: 0.7363\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 37.1\n",
            "  Avg successful length: 30.0\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5308\n",
            "  Alignment loss: 0.4254\n",
            "  Uniformity loss: 4.1053\n",
            "  Accuracy: 54.69%\n",
            "\n",
            "[Epoch 103/300]\n",
            "  Buffer size: 1040\n",
            "  Learning rate: 0.000739\n",
            "  Policy temperature: 0.7316\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 35.0\n",
            "  Avg successful length: 35.0\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5260\n",
            "  Alignment loss: 0.4392\n",
            "  Uniformity loss: 4.0868\n",
            "  Accuracy: 56.25%\n",
            "\n",
            "[Epoch 104/300]\n",
            "  Buffer size: 1050\n",
            "  Learning rate: 0.000734\n",
            "  Policy temperature: 0.7270\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 33.5\n",
            "  Avg successful length: 26.0\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5552\n",
            "  Alignment loss: 0.4792\n",
            "  Uniformity loss: 4.0760\n",
            "  Accuracy: 50.00%\n",
            "\n",
            "[Epoch 105/300]\n",
            "  Buffer size: 1060\n",
            "  Learning rate: 0.000730\n",
            "  Policy temperature: 0.7223\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 30.4\n",
            "  Avg successful length: 30.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5820\n",
            "  Alignment loss: 0.5106\n",
            "  Uniformity loss: 4.0714\n",
            "  Accuracy: 52.34%\n",
            "\n",
            "[Epoch 106/300]\n",
            "  Buffer size: 1070\n",
            "  Learning rate: 0.000725\n",
            "  Policy temperature: 0.7176\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 80.00% (8/10)\n",
            "  Avg trajectory length: 38.2\n",
            "  Avg successful length: 22.5\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5099\n",
            "  Alignment loss: 0.4246\n",
            "  Uniformity loss: 4.0854\n",
            "  Accuracy: 50.78%\n",
            "\n",
            "[Epoch 107/300]\n",
            "  Buffer size: 1080\n",
            "  Learning rate: 0.000720\n",
            "  Policy temperature: 0.7129\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 32.0\n",
            "  Avg successful length: 32.0\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5933\n",
            "  Alignment loss: 0.4862\n",
            "  Uniformity loss: 4.1072\n",
            "  Accuracy: 52.34%\n",
            "\n",
            "[Epoch 108/300]\n",
            "  Buffer size: 1090\n",
            "  Learning rate: 0.000716\n",
            "  Policy temperature: 0.7081\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 24.9\n",
            "  Avg successful length: 24.9\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5196\n",
            "  Alignment loss: 0.4203\n",
            "  Uniformity loss: 4.0993\n",
            "  Accuracy: 60.16%\n",
            "\n",
            "[Epoch 109/300]\n",
            "  Buffer size: 1100\n",
            "  Learning rate: 0.000711\n",
            "  Policy temperature: 0.7034\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 39.8\n",
            "  Avg successful length: 39.8\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5019\n",
            "  Alignment loss: 0.4125\n",
            "  Uniformity loss: 4.0894\n",
            "  Accuracy: 53.91%\n",
            "\n",
            "[Epoch 110/300]\n",
            "  Buffer size: 1110\n",
            "  Learning rate: 0.000706\n",
            "  Policy temperature: 0.6986\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 20.0\n",
            "  Avg successful length: 20.0\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5112\n",
            "  Alignment loss: 0.4136\n",
            "  Uniformity loss: 4.0976\n",
            "  Accuracy: 55.47%\n",
            "\n",
            "[Epoch 111/300]\n",
            "  Buffer size: 1120\n",
            "  Learning rate: 0.000702\n",
            "  Policy temperature: 0.6938\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 43.2\n",
            "  Avg successful length: 36.8\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4921\n",
            "  Alignment loss: 0.3963\n",
            "  Uniformity loss: 4.0958\n",
            "  Accuracy: 56.25%\n",
            "\n",
            "[Epoch 112/300]\n",
            "  Buffer size: 1130\n",
            "  Learning rate: 0.000697\n",
            "  Policy temperature: 0.6889\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 23.8\n",
            "  Avg successful length: 23.8\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5352\n",
            "  Alignment loss: 0.4394\n",
            "  Uniformity loss: 4.0958\n",
            "  Accuracy: 50.78%\n",
            "\n",
            "[Epoch 113/300]\n",
            "  Buffer size: 1140\n",
            "  Learning rate: 0.000692\n",
            "  Policy temperature: 0.6841\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 29.2\n",
            "  Avg successful length: 29.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5971\n",
            "  Alignment loss: 0.5090\n",
            "  Uniformity loss: 4.0881\n",
            "  Accuracy: 53.12%\n",
            "\n",
            "[Epoch 114/300]\n",
            "  Buffer size: 1150\n",
            "  Learning rate: 0.000687\n",
            "  Policy temperature: 0.6792\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 80.00% (8/10)\n",
            "  Avg trajectory length: 31.3\n",
            "  Avg successful length: 13.9\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5632\n",
            "  Alignment loss: 0.4694\n",
            "  Uniformity loss: 4.0938\n",
            "  Accuracy: 52.34%\n",
            "\n",
            "[Epoch 115/300]\n",
            "  Buffer size: 1160\n",
            "  Learning rate: 0.000682\n",
            "  Policy temperature: 0.6743\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 27.9\n",
            "  Avg successful length: 27.9\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5083\n",
            "  Alignment loss: 0.4247\n",
            "  Uniformity loss: 4.0836\n",
            "  Accuracy: 47.66%\n",
            "\n",
            "[Epoch 116/300]\n",
            "  Buffer size: 1170\n",
            "  Learning rate: 0.000678\n",
            "  Policy temperature: 0.6694\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 41.2\n",
            "  Avg successful length: 41.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5444\n",
            "  Alignment loss: 0.4566\n",
            "  Uniformity loss: 4.0878\n",
            "  Accuracy: 59.38%\n",
            "\n",
            "[Epoch 117/300]\n",
            "  Buffer size: 1180\n",
            "  Learning rate: 0.000673\n",
            "  Policy temperature: 0.6644\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 16.6\n",
            "  Avg successful length: 16.6\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4860\n",
            "  Alignment loss: 0.3962\n",
            "  Uniformity loss: 4.0898\n",
            "  Accuracy: 58.59%\n",
            "\n",
            "[Epoch 118/300]\n",
            "  Buffer size: 1190\n",
            "  Learning rate: 0.000668\n",
            "  Policy temperature: 0.6595\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 22.0\n",
            "  Avg successful length: 22.0\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5504\n",
            "  Alignment loss: 0.4648\n",
            "  Uniformity loss: 4.0856\n",
            "  Accuracy: 55.47%\n",
            "\n",
            "[Epoch 119/300]\n",
            "  Buffer size: 1200\n",
            "  Learning rate: 0.000663\n",
            "  Policy temperature: 0.6545\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 33.5\n",
            "  Avg successful length: 33.5\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4924\n",
            "  Alignment loss: 0.4024\n",
            "  Uniformity loss: 4.0901\n",
            "  Accuracy: 63.28%\n",
            "\n",
            "[Epoch 120/300]\n",
            "  Buffer size: 1210\n",
            "  Learning rate: 0.000658\n",
            "  Policy temperature: 0.6495\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 70.00% (7/10)\n",
            "  Avg trajectory length: 65.1\n",
            "  Avg successful length: 49.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5229\n",
            "  Alignment loss: 0.4282\n",
            "  Uniformity loss: 4.0947\n",
            "  Accuracy: 55.47%\n",
            "\n",
            "[Epoch 121/300]\n",
            "  Buffer size: 1220\n",
            "  Learning rate: 0.000653\n",
            "  Policy temperature: 0.6445\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 31.3\n",
            "  Avg successful length: 31.3\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5527\n",
            "  Alignment loss: 0.4587\n",
            "  Uniformity loss: 4.0940\n",
            "  Accuracy: 52.34%\n",
            "\n",
            "[Epoch 122/300]\n",
            "  Buffer size: 1230\n",
            "  Learning rate: 0.000648\n",
            "  Policy temperature: 0.6395\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 23.3\n",
            "  Avg successful length: 14.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5570\n",
            "  Alignment loss: 0.4649\n",
            "  Uniformity loss: 4.0921\n",
            "  Accuracy: 57.03%\n",
            "\n",
            "[Epoch 123/300]\n",
            "  Buffer size: 1240\n",
            "  Learning rate: 0.000643\n",
            "  Policy temperature: 0.6345\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 17.9\n",
            "  Avg successful length: 17.9\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5660\n",
            "  Alignment loss: 0.4741\n",
            "  Uniformity loss: 4.0920\n",
            "  Accuracy: 53.91%\n",
            "\n",
            "[Epoch 124/300]\n",
            "  Buffer size: 1250\n",
            "  Learning rate: 0.000638\n",
            "  Policy temperature: 0.6294\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 29.8\n",
            "  Avg successful length: 21.9\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5731\n",
            "  Alignment loss: 0.4795\n",
            "  Uniformity loss: 4.0936\n",
            "  Accuracy: 52.34%\n",
            "\n",
            "[Epoch 125/300]\n",
            "  Buffer size: 1260\n",
            "  Learning rate: 0.000633\n",
            "  Policy temperature: 0.6243\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 17.6\n",
            "  Avg successful length: 17.6\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6447\n",
            "  Alignment loss: 0.5490\n",
            "  Uniformity loss: 4.0957\n",
            "  Accuracy: 51.56%\n",
            "\n",
            "[Epoch 126/300]\n",
            "  Buffer size: 1270\n",
            "  Learning rate: 0.000628\n",
            "  Policy temperature: 0.6193\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 21.7\n",
            "  Avg successful length: 21.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5622\n",
            "  Alignment loss: 0.4762\n",
            "  Uniformity loss: 4.0859\n",
            "  Accuracy: 51.56%\n",
            "\n",
            "[Epoch 127/300]\n",
            "  Buffer size: 1280\n",
            "  Learning rate: 0.000623\n",
            "  Policy temperature: 0.6142\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 18.2\n",
            "  Avg successful length: 18.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5648\n",
            "  Alignment loss: 0.4660\n",
            "  Uniformity loss: 4.0988\n",
            "  Accuracy: 52.34%\n",
            "\n",
            "[Epoch 128/300]\n",
            "  Buffer size: 1290\n",
            "  Learning rate: 0.000618\n",
            "  Policy temperature: 0.6091\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 25.7\n",
            "  Avg successful length: 25.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5593\n",
            "  Alignment loss: 0.4613\n",
            "  Uniformity loss: 4.0980\n",
            "  Accuracy: 53.91%\n",
            "\n",
            "[Epoch 129/300]\n",
            "  Buffer size: 1300\n",
            "  Learning rate: 0.000613\n",
            "  Policy temperature: 0.6040\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 31.2\n",
            "  Avg successful length: 31.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5392\n",
            "  Alignment loss: 0.4292\n",
            "  Uniformity loss: 4.1101\n",
            "  Accuracy: 56.25%\n",
            "\n",
            "[Epoch 130/300]\n",
            "  Buffer size: 1310\n",
            "  Learning rate: 0.000608\n",
            "  Policy temperature: 0.5988\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 19.2\n",
            "  Avg successful length: 19.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5265\n",
            "  Alignment loss: 0.4333\n",
            "  Uniformity loss: 4.0933\n",
            "  Accuracy: 54.69%\n",
            "\n",
            "[Epoch 131/300]\n",
            "  Buffer size: 1320\n",
            "  Learning rate: 0.000603\n",
            "  Policy temperature: 0.5937\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 22.7\n",
            "  Avg successful length: 22.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5986\n",
            "  Alignment loss: 0.5121\n",
            "  Uniformity loss: 4.0865\n",
            "  Accuracy: 48.44%\n",
            "\n",
            "[Epoch 132/300]\n",
            "  Buffer size: 1330\n",
            "  Learning rate: 0.000598\n",
            "  Policy temperature: 0.5885\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 24.4\n",
            "  Avg successful length: 15.9\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5574\n",
            "  Alignment loss: 0.4538\n",
            "  Uniformity loss: 4.1036\n",
            "  Accuracy: 50.78%\n",
            "\n",
            "[Epoch 133/300]\n",
            "  Buffer size: 1340\n",
            "  Learning rate: 0.000593\n",
            "  Policy temperature: 0.5834\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 23.2\n",
            "  Avg successful length: 23.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5265\n",
            "  Alignment loss: 0.4008\n",
            "  Uniformity loss: 4.1257\n",
            "  Accuracy: 59.38%\n",
            "\n",
            "[Epoch 134/300]\n",
            "  Buffer size: 1350\n",
            "  Learning rate: 0.000588\n",
            "  Policy temperature: 0.5782\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 80.00% (8/10)\n",
            "  Avg trajectory length: 29.1\n",
            "  Avg successful length: 11.1\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4912\n",
            "  Alignment loss: 0.4033\n",
            "  Uniformity loss: 4.0879\n",
            "  Accuracy: 56.25%\n",
            "\n",
            "[Epoch 135/300]\n",
            "  Buffer size: 1360\n",
            "  Learning rate: 0.000582\n",
            "  Policy temperature: 0.5730\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 28.6\n",
            "  Avg successful length: 28.6\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5146\n",
            "  Alignment loss: 0.4180\n",
            "  Uniformity loss: 4.0965\n",
            "  Accuracy: 50.78%\n",
            "\n",
            "[Epoch 136/300]\n",
            "  Buffer size: 1370\n",
            "  Learning rate: 0.000577\n",
            "  Policy temperature: 0.5679\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 17.1\n",
            "  Avg successful length: 17.1\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4654\n",
            "  Alignment loss: 0.3724\n",
            "  Uniformity loss: 4.0929\n",
            "  Accuracy: 60.94%\n",
            "\n",
            "[Epoch 137/300]\n",
            "  Buffer size: 1380\n",
            "  Learning rate: 0.000572\n",
            "  Policy temperature: 0.5627\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 41.2\n",
            "  Avg successful length: 41.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5114\n",
            "  Alignment loss: 0.4262\n",
            "  Uniformity loss: 4.0852\n",
            "  Accuracy: 55.47%\n",
            "\n",
            "[Epoch 138/300]\n",
            "  Buffer size: 1390\n",
            "  Learning rate: 0.000567\n",
            "  Policy temperature: 0.5575\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 21.0\n",
            "  Avg successful length: 21.0\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4915\n",
            "  Alignment loss: 0.3907\n",
            "  Uniformity loss: 4.1008\n",
            "  Accuracy: 52.34%\n",
            "\n",
            "[Epoch 139/300]\n",
            "  Buffer size: 1400\n",
            "  Learning rate: 0.000562\n",
            "  Policy temperature: 0.5523\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 16.0\n",
            "  Avg successful length: 16.0\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5042\n",
            "  Alignment loss: 0.3987\n",
            "  Uniformity loss: 4.1055\n",
            "  Accuracy: 60.16%\n",
            "\n",
            "[Epoch 140/300]\n",
            "  Buffer size: 1410\n",
            "  Learning rate: 0.000557\n",
            "  Policy temperature: 0.5471\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 15.5\n",
            "  Avg successful length: 15.5\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5145\n",
            "  Alignment loss: 0.4093\n",
            "  Uniformity loss: 4.1052\n",
            "  Accuracy: 54.69%\n",
            "\n",
            "[Epoch 141/300]\n",
            "  Buffer size: 1420\n",
            "  Learning rate: 0.000552\n",
            "  Policy temperature: 0.5418\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 20.1\n",
            "  Avg successful length: 20.1\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6226\n",
            "  Alignment loss: 0.5219\n",
            "  Uniformity loss: 4.1007\n",
            "  Accuracy: 45.31%\n",
            "\n",
            "[Epoch 142/300]\n",
            "  Buffer size: 1430\n",
            "  Learning rate: 0.000546\n",
            "  Policy temperature: 0.5366\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 32.4\n",
            "  Avg successful length: 32.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5301\n",
            "  Alignment loss: 0.4318\n",
            "  Uniformity loss: 4.0983\n",
            "  Accuracy: 54.69%\n",
            "\n",
            "[Epoch 143/300]\n",
            "  Buffer size: 1440\n",
            "  Learning rate: 0.000541\n",
            "  Policy temperature: 0.5314\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 17.8\n",
            "  Avg successful length: 17.8\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4973\n",
            "  Alignment loss: 0.3858\n",
            "  Uniformity loss: 4.1115\n",
            "  Accuracy: 61.72%\n",
            "\n",
            "[Epoch 144/300]\n",
            "  Buffer size: 1450\n",
            "  Learning rate: 0.000536\n",
            "  Policy temperature: 0.5262\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 17.3\n",
            "  Avg successful length: 17.3\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5083\n",
            "  Alignment loss: 0.4058\n",
            "  Uniformity loss: 4.1025\n",
            "  Accuracy: 57.81%\n",
            "\n",
            "[Epoch 145/300]\n",
            "  Buffer size: 1460\n",
            "  Learning rate: 0.000531\n",
            "  Policy temperature: 0.5209\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 33.6\n",
            "  Avg successful length: 26.1\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6113\n",
            "  Alignment loss: 0.5304\n",
            "  Uniformity loss: 4.0809\n",
            "  Accuracy: 50.78%\n",
            "\n",
            "[Epoch 146/300]\n",
            "  Buffer size: 1470\n",
            "  Learning rate: 0.000526\n",
            "  Policy temperature: 0.5157\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 27.9\n",
            "  Avg successful length: 27.9\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4736\n",
            "  Alignment loss: 0.3915\n",
            "  Uniformity loss: 4.0821\n",
            "  Accuracy: 57.03%\n",
            "\n",
            "[Epoch 147/300]\n",
            "  Buffer size: 1480\n",
            "  Learning rate: 0.000521\n",
            "  Policy temperature: 0.5105\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 24.4\n",
            "  Avg successful length: 24.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5155\n",
            "  Alignment loss: 0.4117\n",
            "  Uniformity loss: 4.1038\n",
            "  Accuracy: 58.59%\n",
            "\n",
            "[Epoch 148/300]\n",
            "  Buffer size: 1490\n",
            "  Learning rate: 0.000515\n",
            "  Policy temperature: 0.5052\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 30.1\n",
            "  Avg successful length: 30.1\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5213\n",
            "  Alignment loss: 0.4283\n",
            "  Uniformity loss: 4.0929\n",
            "  Accuracy: 57.81%\n",
            "\n",
            "[Epoch 149/300]\n",
            "  Buffer size: 1500\n",
            "  Learning rate: 0.000510\n",
            "  Policy temperature: 0.5000\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 18.4\n",
            "  Avg successful length: 18.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5290\n",
            "  Alignment loss: 0.4246\n",
            "  Uniformity loss: 4.1045\n",
            "  Accuracy: 55.47%\n",
            "\n",
            "[Epoch 150/300]\n",
            "  Buffer size: 1510\n",
            "  Learning rate: 0.000505\n",
            "  Policy temperature: 0.4948\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 15.4\n",
            "  Avg successful length: 15.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5687\n",
            "  Alignment loss: 0.4829\n",
            "  Uniformity loss: 4.0858\n",
            "  Accuracy: 48.44%\n",
            "\n",
            "[Epoch 151/300]\n",
            "  Buffer size: 1520\n",
            "  Learning rate: 0.000500\n",
            "  Policy temperature: 0.4895\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 17.6\n",
            "  Avg successful length: 17.6\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4847\n",
            "  Alignment loss: 0.3832\n",
            "  Uniformity loss: 4.1015\n",
            "  Accuracy: 56.25%\n",
            "\n",
            "[Epoch 152/300]\n",
            "  Buffer size: 1530\n",
            "  Learning rate: 0.000495\n",
            "  Policy temperature: 0.4843\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 25.1\n",
            "  Avg successful length: 16.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5124\n",
            "  Alignment loss: 0.3997\n",
            "  Uniformity loss: 4.1127\n",
            "  Accuracy: 60.94%\n",
            "\n",
            "[Epoch 153/300]\n",
            "  Buffer size: 1540\n",
            "  Learning rate: 0.000489\n",
            "  Policy temperature: 0.4791\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 17.2\n",
            "  Avg successful length: 17.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5311\n",
            "  Alignment loss: 0.4412\n",
            "  Uniformity loss: 4.0900\n",
            "  Accuracy: 51.56%\n",
            "\n",
            "[Epoch 154/300]\n",
            "  Buffer size: 1550\n",
            "  Learning rate: 0.000484\n",
            "  Policy temperature: 0.4738\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 35.2\n",
            "  Avg successful length: 35.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5079\n",
            "  Alignment loss: 0.4193\n",
            "  Uniformity loss: 4.0886\n",
            "  Accuracy: 50.00%\n",
            "\n",
            "[Epoch 155/300]\n",
            "  Buffer size: 1560\n",
            "  Learning rate: 0.000479\n",
            "  Policy temperature: 0.4686\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 16.6\n",
            "  Avg successful length: 16.6\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5448\n",
            "  Alignment loss: 0.4472\n",
            "  Uniformity loss: 4.0975\n",
            "  Accuracy: 53.12%\n",
            "\n",
            "[Epoch 156/300]\n",
            "  Buffer size: 1570\n",
            "  Learning rate: 0.000474\n",
            "  Policy temperature: 0.4634\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 29.6\n",
            "  Avg successful length: 29.6\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5129\n",
            "  Alignment loss: 0.4240\n",
            "  Uniformity loss: 4.0889\n",
            "  Accuracy: 50.78%\n",
            "\n",
            "[Epoch 157/300]\n",
            "  Buffer size: 1580\n",
            "  Learning rate: 0.000469\n",
            "  Policy temperature: 0.4582\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 16.3\n",
            "  Avg successful length: 16.3\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5927\n",
            "  Alignment loss: 0.4940\n",
            "  Uniformity loss: 4.0987\n",
            "  Accuracy: 42.97%\n",
            "\n",
            "[Epoch 158/300]\n",
            "  Buffer size: 1590\n",
            "  Learning rate: 0.000464\n",
            "  Policy temperature: 0.4529\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 22.6\n",
            "  Avg successful length: 22.6\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5725\n",
            "  Alignment loss: 0.4795\n",
            "  Uniformity loss: 4.0930\n",
            "  Accuracy: 56.25%\n",
            "\n",
            "[Epoch 159/300]\n",
            "  Buffer size: 1600\n",
            "  Learning rate: 0.000458\n",
            "  Policy temperature: 0.4477\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 34.8\n",
            "  Avg successful length: 27.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5521\n",
            "  Alignment loss: 0.4504\n",
            "  Uniformity loss: 4.1016\n",
            "  Accuracy: 53.12%\n",
            "\n",
            "[Epoch 160/300]\n",
            "  Buffer size: 1610\n",
            "  Learning rate: 0.000453\n",
            "  Policy temperature: 0.4425\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 19.6\n",
            "  Avg successful length: 19.6\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6071\n",
            "  Alignment loss: 0.4826\n",
            "  Uniformity loss: 4.1245\n",
            "  Accuracy: 50.78%\n",
            "\n",
            "[Epoch 161/300]\n",
            "  Buffer size: 1620\n",
            "  Learning rate: 0.000448\n",
            "  Policy temperature: 0.4373\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 32.1\n",
            "  Avg successful length: 24.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5707\n",
            "  Alignment loss: 0.4772\n",
            "  Uniformity loss: 4.0935\n",
            "  Accuracy: 53.12%\n",
            "\n",
            "[Epoch 162/300]\n",
            "  Buffer size: 1630\n",
            "  Learning rate: 0.000443\n",
            "  Policy temperature: 0.4321\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 23.8\n",
            "  Avg successful length: 23.8\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5651\n",
            "  Alignment loss: 0.4670\n",
            "  Uniformity loss: 4.0982\n",
            "  Accuracy: 49.22%\n",
            "\n",
            "[Epoch 163/300]\n",
            "  Buffer size: 1640\n",
            "  Learning rate: 0.000438\n",
            "  Policy temperature: 0.4270\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 19.5\n",
            "  Avg successful length: 19.5\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5277\n",
            "  Alignment loss: 0.4373\n",
            "  Uniformity loss: 4.0903\n",
            "  Accuracy: 52.34%\n",
            "\n",
            "[Epoch 164/300]\n",
            "  Buffer size: 1650\n",
            "  Learning rate: 0.000433\n",
            "  Policy temperature: 0.4218\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 26.9\n",
            "  Avg successful length: 26.9\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4677\n",
            "  Alignment loss: 0.3596\n",
            "  Uniformity loss: 4.1081\n",
            "  Accuracy: 62.50%\n",
            "\n",
            "[Epoch 165/300]\n",
            "  Buffer size: 1660\n",
            "  Learning rate: 0.000428\n",
            "  Policy temperature: 0.4166\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 24.8\n",
            "  Avg successful length: 24.8\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6284\n",
            "  Alignment loss: 0.5357\n",
            "  Uniformity loss: 4.0927\n",
            "  Accuracy: 49.22%\n",
            "\n",
            "[Epoch 166/300]\n",
            "  Buffer size: 1670\n",
            "  Learning rate: 0.000422\n",
            "  Policy temperature: 0.4115\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 24.8\n",
            "  Avg successful length: 24.8\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5310\n",
            "  Alignment loss: 0.4320\n",
            "  Uniformity loss: 4.0990\n",
            "  Accuracy: 50.00%\n",
            "\n",
            "[Epoch 167/300]\n",
            "  Buffer size: 1680\n",
            "  Learning rate: 0.000417\n",
            "  Policy temperature: 0.4063\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 21.7\n",
            "  Avg successful length: 21.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5669\n",
            "  Alignment loss: 0.4554\n",
            "  Uniformity loss: 4.1115\n",
            "  Accuracy: 53.91%\n",
            "\n",
            "[Epoch 168/300]\n",
            "  Buffer size: 1690\n",
            "  Learning rate: 0.000412\n",
            "  Policy temperature: 0.4012\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 24.9\n",
            "  Avg successful length: 24.9\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5608\n",
            "  Alignment loss: 0.4723\n",
            "  Uniformity loss: 4.0885\n",
            "  Accuracy: 50.78%\n",
            "\n",
            "[Epoch 169/300]\n",
            "  Buffer size: 1700\n",
            "  Learning rate: 0.000407\n",
            "  Policy temperature: 0.3960\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 23.4\n",
            "  Avg successful length: 23.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5012\n",
            "  Alignment loss: 0.4059\n",
            "  Uniformity loss: 4.0953\n",
            "  Accuracy: 55.47%\n",
            "\n",
            "[Epoch 170/300]\n",
            "  Buffer size: 1710\n",
            "  Learning rate: 0.000402\n",
            "  Policy temperature: 0.3909\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 10.9\n",
            "  Avg successful length: 10.9\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5534\n",
            "  Alignment loss: 0.4549\n",
            "  Uniformity loss: 4.0984\n",
            "  Accuracy: 56.25%\n",
            "\n",
            "[Epoch 171/300]\n",
            "  Buffer size: 1720\n",
            "  Learning rate: 0.000397\n",
            "  Policy temperature: 0.3858\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 37.6\n",
            "  Avg successful length: 37.6\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5066\n",
            "  Alignment loss: 0.4085\n",
            "  Uniformity loss: 4.0981\n",
            "  Accuracy: 57.81%\n",
            "\n",
            "[Epoch 172/300]\n",
            "  Buffer size: 1730\n",
            "  Learning rate: 0.000392\n",
            "  Policy temperature: 0.3807\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 15.5\n",
            "  Avg successful length: 15.5\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5484\n",
            "  Alignment loss: 0.4344\n",
            "  Uniformity loss: 4.1141\n",
            "  Accuracy: 53.12%\n",
            "\n",
            "[Epoch 173/300]\n",
            "  Buffer size: 1740\n",
            "  Learning rate: 0.000387\n",
            "  Policy temperature: 0.3757\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 18.6\n",
            "  Avg successful length: 18.6\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5184\n",
            "  Alignment loss: 0.4227\n",
            "  Uniformity loss: 4.0957\n",
            "  Accuracy: 53.91%\n",
            "\n",
            "[Epoch 174/300]\n",
            "  Buffer size: 1750\n",
            "  Learning rate: 0.000382\n",
            "  Policy temperature: 0.3706\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 20.7\n",
            "  Avg successful length: 20.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6175\n",
            "  Alignment loss: 0.5111\n",
            "  Uniformity loss: 4.1064\n",
            "  Accuracy: 47.66%\n",
            "\n",
            "[Epoch 175/300]\n",
            "  Buffer size: 1760\n",
            "  Learning rate: 0.000377\n",
            "  Policy temperature: 0.3655\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 20.7\n",
            "  Avg successful length: 20.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5669\n",
            "  Alignment loss: 0.4783\n",
            "  Uniformity loss: 4.0886\n",
            "  Accuracy: 50.78%\n",
            "\n",
            "[Epoch 176/300]\n",
            "  Buffer size: 1770\n",
            "  Learning rate: 0.000372\n",
            "  Policy temperature: 0.3605\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 24.2\n",
            "  Avg successful length: 24.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5310\n",
            "  Alignment loss: 0.4381\n",
            "  Uniformity loss: 4.0929\n",
            "  Accuracy: 53.12%\n",
            "\n",
            "[Epoch 177/300]\n",
            "  Buffer size: 1780\n",
            "  Learning rate: 0.000367\n",
            "  Policy temperature: 0.3555\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 27.1\n",
            "  Avg successful length: 27.1\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5314\n",
            "  Alignment loss: 0.4205\n",
            "  Uniformity loss: 4.1109\n",
            "  Accuracy: 56.25%\n",
            "\n",
            "[Epoch 178/300]\n",
            "  Buffer size: 1790\n",
            "  Learning rate: 0.000362\n",
            "  Policy temperature: 0.3505\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 15.8\n",
            "  Avg successful length: 15.8\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5487\n",
            "  Alignment loss: 0.4437\n",
            "  Uniformity loss: 4.1049\n",
            "  Accuracy: 53.12%\n",
            "\n",
            "[Epoch 179/300]\n",
            "  Buffer size: 1800\n",
            "  Learning rate: 0.000357\n",
            "  Policy temperature: 0.3455\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 21.2\n",
            "  Avg successful length: 21.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5360\n",
            "  Alignment loss: 0.4424\n",
            "  Uniformity loss: 4.0936\n",
            "  Accuracy: 53.12%\n",
            "\n",
            "[Epoch 180/300]\n",
            "  Buffer size: 1810\n",
            "  Learning rate: 0.000352\n",
            "  Policy temperature: 0.3405\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 23.1\n",
            "  Avg successful length: 23.1\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5226\n",
            "  Alignment loss: 0.4236\n",
            "  Uniformity loss: 4.0989\n",
            "  Accuracy: 58.59%\n",
            "\n",
            "[Epoch 181/300]\n",
            "  Buffer size: 1820\n",
            "  Learning rate: 0.000347\n",
            "  Policy temperature: 0.3356\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 16.4\n",
            "  Avg successful length: 16.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4447\n",
            "  Alignment loss: 0.3483\n",
            "  Uniformity loss: 4.0964\n",
            "  Accuracy: 61.72%\n",
            "\n",
            "[Epoch 182/300]\n",
            "  Buffer size: 1830\n",
            "  Learning rate: 0.000342\n",
            "  Policy temperature: 0.3306\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 17.9\n",
            "  Avg successful length: 17.9\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4309\n",
            "  Alignment loss: 0.3458\n",
            "  Uniformity loss: 4.0851\n",
            "  Accuracy: 57.03%\n",
            "\n",
            "[Epoch 183/300]\n",
            "  Buffer size: 1840\n",
            "  Learning rate: 0.000337\n",
            "  Policy temperature: 0.3257\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 27.0\n",
            "  Avg successful length: 27.0\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4559\n",
            "  Alignment loss: 0.3614\n",
            "  Uniformity loss: 4.0945\n",
            "  Accuracy: 59.38%\n",
            "\n",
            "[Epoch 184/300]\n",
            "  Buffer size: 1850\n",
            "  Learning rate: 0.000332\n",
            "  Policy temperature: 0.3208\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 23.8\n",
            "  Avg successful length: 23.8\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5210\n",
            "  Alignment loss: 0.4208\n",
            "  Uniformity loss: 4.1002\n",
            "  Accuracy: 50.00%\n",
            "\n",
            "[Epoch 185/300]\n",
            "  Buffer size: 1860\n",
            "  Learning rate: 0.000328\n",
            "  Policy temperature: 0.3159\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 17.1\n",
            "  Avg successful length: 17.1\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5221\n",
            "  Alignment loss: 0.4253\n",
            "  Uniformity loss: 4.0968\n",
            "  Accuracy: 53.91%\n",
            "\n",
            "[Epoch 186/300]\n",
            "  Buffer size: 1870\n",
            "  Learning rate: 0.000323\n",
            "  Policy temperature: 0.3111\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 14.8\n",
            "  Avg successful length: 14.8\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5629\n",
            "  Alignment loss: 0.4592\n",
            "  Uniformity loss: 4.1037\n",
            "  Accuracy: 44.53%\n",
            "\n",
            "[Epoch 187/300]\n",
            "  Buffer size: 1880\n",
            "  Learning rate: 0.000318\n",
            "  Policy temperature: 0.3062\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 19.2\n",
            "  Avg successful length: 19.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4854\n",
            "  Alignment loss: 0.3899\n",
            "  Uniformity loss: 4.0955\n",
            "  Accuracy: 53.12%\n",
            "\n",
            "[Epoch 188/300]\n",
            "  Buffer size: 1890\n",
            "  Learning rate: 0.000313\n",
            "  Policy temperature: 0.3014\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 9.3\n",
            "  Avg successful length: 9.3\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5219\n",
            "  Alignment loss: 0.4243\n",
            "  Uniformity loss: 4.0976\n",
            "  Accuracy: 50.00%\n",
            "\n",
            "[Epoch 189/300]\n",
            "  Buffer size: 1900\n",
            "  Learning rate: 0.000308\n",
            "  Policy temperature: 0.2966\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 15.1\n",
            "  Avg successful length: 15.1\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5451\n",
            "  Alignment loss: 0.4546\n",
            "  Uniformity loss: 4.0905\n",
            "  Accuracy: 48.44%\n",
            "\n",
            "[Epoch 190/300]\n",
            "  Buffer size: 1910\n",
            "  Learning rate: 0.000304\n",
            "  Policy temperature: 0.2919\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 15.5\n",
            "  Avg successful length: 15.5\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5398\n",
            "  Alignment loss: 0.4422\n",
            "  Uniformity loss: 4.0976\n",
            "  Accuracy: 55.47%\n",
            "\n",
            "[Epoch 191/300]\n",
            "  Buffer size: 1920\n",
            "  Learning rate: 0.000299\n",
            "  Policy temperature: 0.2871\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 17.2\n",
            "  Avg successful length: 17.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5797\n",
            "  Alignment loss: 0.4860\n",
            "  Uniformity loss: 4.0937\n",
            "  Accuracy: 54.69%\n",
            "\n",
            "[Epoch 192/300]\n",
            "  Buffer size: 1930\n",
            "  Learning rate: 0.000294\n",
            "  Policy temperature: 0.2824\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 22.6\n",
            "  Avg successful length: 22.6\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5539\n",
            "  Alignment loss: 0.4575\n",
            "  Uniformity loss: 4.0965\n",
            "  Accuracy: 48.44%\n",
            "\n",
            "[Epoch 193/300]\n",
            "  Buffer size: 1940\n",
            "  Learning rate: 0.000290\n",
            "  Policy temperature: 0.2777\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 12.3\n",
            "  Avg successful length: 12.3\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5932\n",
            "  Alignment loss: 0.4992\n",
            "  Uniformity loss: 4.0940\n",
            "  Accuracy: 52.34%\n",
            "\n",
            "[Epoch 194/300]\n",
            "  Buffer size: 1950\n",
            "  Learning rate: 0.000285\n",
            "  Policy temperature: 0.2730\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 19.4\n",
            "  Avg successful length: 19.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4861\n",
            "  Alignment loss: 0.3949\n",
            "  Uniformity loss: 4.0912\n",
            "  Accuracy: 59.38%\n",
            "\n",
            "[Epoch 195/300]\n",
            "  Buffer size: 1960\n",
            "  Learning rate: 0.000280\n",
            "  Policy temperature: 0.2684\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 18.0\n",
            "  Avg successful length: 18.0\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6435\n",
            "  Alignment loss: 0.5429\n",
            "  Uniformity loss: 4.1006\n",
            "  Accuracy: 47.66%\n",
            "\n",
            "[Epoch 196/300]\n",
            "  Buffer size: 1970\n",
            "  Learning rate: 0.000276\n",
            "  Policy temperature: 0.2637\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 14.8\n",
            "  Avg successful length: 14.8\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5329\n",
            "  Alignment loss: 0.4328\n",
            "  Uniformity loss: 4.1001\n",
            "  Accuracy: 53.12%\n",
            "\n",
            "[Epoch 197/300]\n",
            "  Buffer size: 1980\n",
            "  Learning rate: 0.000271\n",
            "  Policy temperature: 0.2591\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 21.5\n",
            "  Avg successful length: 21.5\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5376\n",
            "  Alignment loss: 0.4434\n",
            "  Uniformity loss: 4.0942\n",
            "  Accuracy: 55.47%\n",
            "\n",
            "[Epoch 198/300]\n",
            "  Buffer size: 1990\n",
            "  Learning rate: 0.000267\n",
            "  Policy temperature: 0.2545\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 13.8\n",
            "  Avg successful length: 13.8\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4970\n",
            "  Alignment loss: 0.4042\n",
            "  Uniformity loss: 4.0927\n",
            "  Accuracy: 53.91%\n",
            "\n",
            "[Epoch 199/300]\n",
            "  Buffer size: 2000\n",
            "  Learning rate: 0.000262\n",
            "  Policy temperature: 0.2500\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 8.7\n",
            "  Avg successful length: 8.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5266\n",
            "  Alignment loss: 0.4129\n",
            "  Uniformity loss: 4.1137\n",
            "  Accuracy: 53.91%\n",
            "\n",
            "[Epoch 200/300]\n",
            "  Buffer size: 2010\n",
            "  Learning rate: 0.000257\n",
            "  Policy temperature: 0.2455\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 24.4\n",
            "  Avg successful length: 24.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5791\n",
            "  Alignment loss: 0.4927\n",
            "  Uniformity loss: 4.0864\n",
            "  Accuracy: 50.78%\n",
            "\n",
            "[Epoch 201/300]\n",
            "  Buffer size: 2020\n",
            "  Learning rate: 0.000253\n",
            "  Policy temperature: 0.2410\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 18.7\n",
            "  Avg successful length: 18.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6015\n",
            "  Alignment loss: 0.5049\n",
            "  Uniformity loss: 4.0966\n",
            "  Accuracy: 49.22%\n",
            "\n",
            "[Epoch 202/300]\n",
            "  Buffer size: 2030\n",
            "  Learning rate: 0.000249\n",
            "  Policy temperature: 0.2365\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 9.9\n",
            "  Avg successful length: 9.9\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5594\n",
            "  Alignment loss: 0.4529\n",
            "  Uniformity loss: 4.1065\n",
            "  Accuracy: 53.91%\n",
            "\n",
            "[Epoch 203/300]\n",
            "  Buffer size: 2040\n",
            "  Learning rate: 0.000244\n",
            "  Policy temperature: 0.2321\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 14.6\n",
            "  Avg successful length: 14.6\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5970\n",
            "  Alignment loss: 0.5124\n",
            "  Uniformity loss: 4.0845\n",
            "  Accuracy: 50.78%\n",
            "\n",
            "[Epoch 204/300]\n",
            "  Buffer size: 2050\n",
            "  Learning rate: 0.000240\n",
            "  Policy temperature: 0.2277\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 21.9\n",
            "  Avg successful length: 13.1\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5514\n",
            "  Alignment loss: 0.4700\n",
            "  Uniformity loss: 4.0814\n",
            "  Accuracy: 52.34%\n",
            "\n",
            "[Epoch 205/300]\n",
            "  Buffer size: 2060\n",
            "  Learning rate: 0.000235\n",
            "  Policy temperature: 0.2233\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 20.7\n",
            "  Avg successful length: 20.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5223\n",
            "  Alignment loss: 0.4286\n",
            "  Uniformity loss: 4.0937\n",
            "  Accuracy: 53.91%\n",
            "\n",
            "[Epoch 206/300]\n",
            "  Buffer size: 2070\n",
            "  Learning rate: 0.000231\n",
            "  Policy temperature: 0.2190\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 11.7\n",
            "  Avg successful length: 11.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5475\n",
            "  Alignment loss: 0.4587\n",
            "  Uniformity loss: 4.0888\n",
            "  Accuracy: 53.12%\n",
            "\n",
            "[Epoch 207/300]\n",
            "  Buffer size: 2080\n",
            "  Learning rate: 0.000227\n",
            "  Policy temperature: 0.2146\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 29.2\n",
            "  Avg successful length: 29.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5906\n",
            "  Alignment loss: 0.5102\n",
            "  Uniformity loss: 4.0803\n",
            "  Accuracy: 47.66%\n",
            "\n",
            "[Epoch 208/300]\n",
            "  Buffer size: 2090\n",
            "  Learning rate: 0.000222\n",
            "  Policy temperature: 0.2104\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 14.1\n",
            "  Avg successful length: 14.1\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5931\n",
            "  Alignment loss: 0.5040\n",
            "  Uniformity loss: 4.0891\n",
            "  Accuracy: 47.66%\n",
            "\n",
            "[Epoch 209/300]\n",
            "  Buffer size: 2100\n",
            "  Learning rate: 0.000218\n",
            "  Policy temperature: 0.2061\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 13.3\n",
            "  Avg successful length: 13.3\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5905\n",
            "  Alignment loss: 0.4917\n",
            "  Uniformity loss: 4.0988\n",
            "  Accuracy: 50.00%\n",
            "\n",
            "[Epoch 210/300]\n",
            "  Buffer size: 2110\n",
            "  Learning rate: 0.000214\n",
            "  Policy temperature: 0.2019\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 17.0\n",
            "  Avg successful length: 17.0\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5306\n",
            "  Alignment loss: 0.4316\n",
            "  Uniformity loss: 4.0989\n",
            "  Accuracy: 53.91%\n",
            "\n",
            "[Epoch 211/300]\n",
            "  Buffer size: 2120\n",
            "  Learning rate: 0.000210\n",
            "  Policy temperature: 0.1977\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 11.7\n",
            "  Avg successful length: 11.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5214\n",
            "  Alignment loss: 0.4098\n",
            "  Uniformity loss: 4.1116\n",
            "  Accuracy: 56.25%\n",
            "\n",
            "[Epoch 212/300]\n",
            "  Buffer size: 2130\n",
            "  Learning rate: 0.000206\n",
            "  Policy temperature: 0.1935\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 10.0\n",
            "  Avg successful length: 10.0\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.7194\n",
            "  Alignment loss: 0.6065\n",
            "  Uniformity loss: 4.1129\n",
            "  Accuracy: 41.41%\n",
            "\n",
            "[Epoch 213/300]\n",
            "  Buffer size: 2140\n",
            "  Learning rate: 0.000202\n",
            "  Policy temperature: 0.1894\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 18.2\n",
            "  Avg successful length: 18.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5413\n",
            "  Alignment loss: 0.4423\n",
            "  Uniformity loss: 4.0990\n",
            "  Accuracy: 57.81%\n",
            "\n",
            "[Epoch 214/300]\n",
            "  Buffer size: 2150\n",
            "  Learning rate: 0.000198\n",
            "  Policy temperature: 0.1853\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 17.2\n",
            "  Avg successful length: 17.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6746\n",
            "  Alignment loss: 0.5668\n",
            "  Uniformity loss: 4.1078\n",
            "  Accuracy: 36.72%\n",
            "\n",
            "[Epoch 215/300]\n",
            "  Buffer size: 2160\n",
            "  Learning rate: 0.000193\n",
            "  Policy temperature: 0.1813\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 13.8\n",
            "  Avg successful length: 13.8\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5615\n",
            "  Alignment loss: 0.4458\n",
            "  Uniformity loss: 4.1157\n",
            "  Accuracy: 50.78%\n",
            "\n",
            "[Epoch 216/300]\n",
            "  Buffer size: 2170\n",
            "  Learning rate: 0.000189\n",
            "  Policy temperature: 0.1773\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 11.0\n",
            "  Avg successful length: 11.0\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5384\n",
            "  Alignment loss: 0.4310\n",
            "  Uniformity loss: 4.1074\n",
            "  Accuracy: 46.88%\n",
            "\n",
            "[Epoch 217/300]\n",
            "  Buffer size: 2180\n",
            "  Learning rate: 0.000185\n",
            "  Policy temperature: 0.1733\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 13.2\n",
            "  Avg successful length: 13.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5601\n",
            "  Alignment loss: 0.4685\n",
            "  Uniformity loss: 4.0916\n",
            "  Accuracy: 51.56%\n",
            "\n",
            "[Epoch 218/300]\n",
            "  Buffer size: 2190\n",
            "  Learning rate: 0.000182\n",
            "  Policy temperature: 0.1693\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 11.1\n",
            "  Avg successful length: 11.1\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5713\n",
            "  Alignment loss: 0.4838\n",
            "  Uniformity loss: 4.0875\n",
            "  Accuracy: 49.22%\n",
            "\n",
            "[Epoch 219/300]\n",
            "  Buffer size: 2200\n",
            "  Learning rate: 0.000178\n",
            "  Policy temperature: 0.1654\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 11.0\n",
            "  Avg successful length: 11.0\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5391\n",
            "  Alignment loss: 0.4294\n",
            "  Uniformity loss: 4.1097\n",
            "  Accuracy: 50.00%\n",
            "\n",
            "[Epoch 220/300]\n",
            "  Buffer size: 2210\n",
            "  Learning rate: 0.000174\n",
            "  Policy temperature: 0.1616\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 8.6\n",
            "  Avg successful length: 8.6\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6202\n",
            "  Alignment loss: 0.5227\n",
            "  Uniformity loss: 4.0974\n",
            "  Accuracy: 40.62%\n",
            "\n",
            "[Epoch 221/300]\n",
            "  Buffer size: 2220\n",
            "  Learning rate: 0.000170\n",
            "  Policy temperature: 0.1577\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 14.1\n",
            "  Avg successful length: 14.1\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5865\n",
            "  Alignment loss: 0.4952\n",
            "  Uniformity loss: 4.0913\n",
            "  Accuracy: 48.44%\n",
            "\n",
            "[Epoch 222/300]\n",
            "  Buffer size: 2230\n",
            "  Learning rate: 0.000166\n",
            "  Policy temperature: 0.1539\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 13.1\n",
            "  Avg successful length: 13.1\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5841\n",
            "  Alignment loss: 0.4818\n",
            "  Uniformity loss: 4.1024\n",
            "  Accuracy: 51.56%\n",
            "\n",
            "[Epoch 223/300]\n",
            "  Buffer size: 2240\n",
            "  Learning rate: 0.000162\n",
            "  Policy temperature: 0.1502\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 8.4\n",
            "  Avg successful length: 8.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5454\n",
            "  Alignment loss: 0.4510\n",
            "  Uniformity loss: 4.0944\n",
            "  Accuracy: 50.78%\n",
            "\n",
            "[Epoch 224/300]\n",
            "  Buffer size: 2250\n",
            "  Learning rate: 0.000159\n",
            "  Policy temperature: 0.1464\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 14.1\n",
            "  Avg successful length: 14.1\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5227\n",
            "  Alignment loss: 0.4158\n",
            "  Uniformity loss: 4.1069\n",
            "  Accuracy: 55.47%\n",
            "\n",
            "[Epoch 225/300]\n",
            "  Buffer size: 2260\n",
            "  Learning rate: 0.000155\n",
            "  Policy temperature: 0.1428\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 12.1\n",
            "  Avg successful length: 12.1\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5504\n",
            "  Alignment loss: 0.4617\n",
            "  Uniformity loss: 4.0886\n",
            "  Accuracy: 47.66%\n",
            "\n",
            "[Epoch 226/300]\n",
            "  Buffer size: 2270\n",
            "  Learning rate: 0.000151\n",
            "  Policy temperature: 0.1391\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 11.8\n",
            "  Avg successful length: 11.8\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5356\n",
            "  Alignment loss: 0.4372\n",
            "  Uniformity loss: 4.0984\n",
            "  Accuracy: 47.66%\n",
            "\n",
            "[Epoch 227/300]\n",
            "  Buffer size: 2280\n",
            "  Learning rate: 0.000148\n",
            "  Policy temperature: 0.1355\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 13.3\n",
            "  Avg successful length: 13.3\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4978\n",
            "  Alignment loss: 0.4048\n",
            "  Uniformity loss: 4.0931\n",
            "  Accuracy: 51.56%\n",
            "\n",
            "[Epoch 228/300]\n",
            "  Buffer size: 2290\n",
            "  Learning rate: 0.000144\n",
            "  Policy temperature: 0.1320\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 10.7\n",
            "  Avg successful length: 10.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5947\n",
            "  Alignment loss: 0.5019\n",
            "  Uniformity loss: 4.0928\n",
            "  Accuracy: 42.19%\n",
            "\n",
            "[Epoch 229/300]\n",
            "  Buffer size: 2300\n",
            "  Learning rate: 0.000141\n",
            "  Policy temperature: 0.1284\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 10.6\n",
            "  Avg successful length: 10.6\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5360\n",
            "  Alignment loss: 0.4416\n",
            "  Uniformity loss: 4.0944\n",
            "  Accuracy: 50.00%\n",
            "\n",
            "[Epoch 230/300]\n",
            "  Buffer size: 2310\n",
            "  Learning rate: 0.000137\n",
            "  Policy temperature: 0.1249\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 9.0\n",
            "  Avg successful length: 9.0\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5622\n",
            "  Alignment loss: 0.4434\n",
            "  Uniformity loss: 4.1188\n",
            "  Accuracy: 48.44%\n",
            "\n",
            "[Epoch 231/300]\n",
            "  Buffer size: 2320\n",
            "  Learning rate: 0.000134\n",
            "  Policy temperature: 0.1215\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 9.2\n",
            "  Avg successful length: 9.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5456\n",
            "  Alignment loss: 0.4496\n",
            "  Uniformity loss: 4.0960\n",
            "  Accuracy: 50.78%\n",
            "\n",
            "[Epoch 232/300]\n",
            "  Buffer size: 2330\n",
            "  Learning rate: 0.000130\n",
            "  Policy temperature: 0.1181\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 7.4\n",
            "  Avg successful length: 7.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5307\n",
            "  Alignment loss: 0.4409\n",
            "  Uniformity loss: 4.0898\n",
            "  Accuracy: 54.69%\n",
            "\n",
            "[Epoch 233/300]\n",
            "  Buffer size: 2340\n",
            "  Learning rate: 0.000127\n",
            "  Policy temperature: 0.1147\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 6.6\n",
            "  Avg successful length: 6.6\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5564\n",
            "  Alignment loss: 0.4621\n",
            "  Uniformity loss: 4.0943\n",
            "  Accuracy: 49.22%\n",
            "\n",
            "[Epoch 234/300]\n",
            "  Buffer size: 2350\n",
            "  Learning rate: 0.000124\n",
            "  Policy temperature: 0.1114\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 9.9\n",
            "  Avg successful length: 9.9\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5787\n",
            "  Alignment loss: 0.4842\n",
            "  Uniformity loss: 4.0945\n",
            "  Accuracy: 48.44%\n",
            "\n",
            "[Epoch 235/300]\n",
            "  Buffer size: 2360\n",
            "  Learning rate: 0.000120\n",
            "  Policy temperature: 0.1082\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 11.4\n",
            "  Avg successful length: 11.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5631\n",
            "  Alignment loss: 0.4516\n",
            "  Uniformity loss: 4.1115\n",
            "  Accuracy: 53.91%\n",
            "\n",
            "[Epoch 236/300]\n",
            "  Buffer size: 2370\n",
            "  Learning rate: 0.000117\n",
            "  Policy temperature: 0.1049\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 7.8\n",
            "  Avg successful length: 7.8\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5709\n",
            "  Alignment loss: 0.4730\n",
            "  Uniformity loss: 4.0980\n",
            "  Accuracy: 39.06%\n",
            "\n",
            "[Epoch 237/300]\n",
            "  Buffer size: 2380\n",
            "  Learning rate: 0.000114\n",
            "  Policy temperature: 0.1017\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 7.9\n",
            "  Avg successful length: 7.9\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5205\n",
            "  Alignment loss: 0.4238\n",
            "  Uniformity loss: 4.0967\n",
            "  Accuracy: 47.66%\n",
            "\n",
            "[Epoch 238/300]\n",
            "  Buffer size: 2390\n",
            "  Learning rate: 0.000111\n",
            "  Policy temperature: 0.0986\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 8.0\n",
            "  Avg successful length: 8.0\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5618\n",
            "  Alignment loss: 0.4668\n",
            "  Uniformity loss: 4.0949\n",
            "  Accuracy: 46.88%\n",
            "\n",
            "[Epoch 239/300]\n",
            "  Buffer size: 2400\n",
            "  Learning rate: 0.000108\n",
            "  Policy temperature: 0.0955\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 10.7\n",
            "  Avg successful length: 10.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5068\n",
            "  Alignment loss: 0.3993\n",
            "  Uniformity loss: 4.1075\n",
            "  Accuracy: 50.78%\n",
            "\n",
            "[Epoch 240/300]\n",
            "  Buffer size: 2410\n",
            "  Learning rate: 0.000105\n",
            "  Policy temperature: 0.0924\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 9.3\n",
            "  Avg successful length: 9.3\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5684\n",
            "  Alignment loss: 0.4685\n",
            "  Uniformity loss: 4.0999\n",
            "  Accuracy: 47.66%\n",
            "\n",
            "[Epoch 241/300]\n",
            "  Buffer size: 2420\n",
            "  Learning rate: 0.000102\n",
            "  Policy temperature: 0.0894\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 11.1\n",
            "  Avg successful length: 11.1\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5435\n",
            "  Alignment loss: 0.4428\n",
            "  Uniformity loss: 4.1007\n",
            "  Accuracy: 53.12%\n",
            "\n",
            "[Epoch 242/300]\n",
            "  Buffer size: 2430\n",
            "  Learning rate: 0.000099\n",
            "  Policy temperature: 0.0865\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 7.9\n",
            "  Avg successful length: 7.9\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5489\n",
            "  Alignment loss: 0.4535\n",
            "  Uniformity loss: 4.0954\n",
            "  Accuracy: 47.66%\n",
            "\n",
            "[Epoch 243/300]\n",
            "  Buffer size: 2440\n",
            "  Learning rate: 0.000096\n",
            "  Policy temperature: 0.0835\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 8.4\n",
            "  Avg successful length: 8.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4440\n",
            "  Alignment loss: 0.3506\n",
            "  Uniformity loss: 4.0934\n",
            "  Accuracy: 56.25%\n",
            "\n",
            "[Epoch 244/300]\n",
            "  Buffer size: 2450\n",
            "  Learning rate: 0.000093\n",
            "  Policy temperature: 0.0807\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 8.4\n",
            "  Avg successful length: 8.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6114\n",
            "  Alignment loss: 0.5172\n",
            "  Uniformity loss: 4.0942\n",
            "  Accuracy: 45.31%\n",
            "\n",
            "[Epoch 245/300]\n",
            "  Buffer size: 2460\n",
            "  Learning rate: 0.000090\n",
            "  Policy temperature: 0.0778\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 13.0\n",
            "  Avg successful length: 13.0\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5171\n",
            "  Alignment loss: 0.4187\n",
            "  Uniformity loss: 4.0984\n",
            "  Accuracy: 53.91%\n",
            "\n",
            "[Epoch 246/300]\n",
            "  Buffer size: 2470\n",
            "  Learning rate: 0.000087\n",
            "  Policy temperature: 0.0751\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 7.3\n",
            "  Avg successful length: 7.3\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5761\n",
            "  Alignment loss: 0.4779\n",
            "  Uniformity loss: 4.0982\n",
            "  Accuracy: 50.00%\n",
            "\n",
            "[Epoch 247/300]\n",
            "  Buffer size: 2480\n",
            "  Learning rate: 0.000084\n",
            "  Policy temperature: 0.0723\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 7.3\n",
            "  Avg successful length: 7.3\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5761\n",
            "  Alignment loss: 0.4921\n",
            "  Uniformity loss: 4.0840\n",
            "  Accuracy: 46.09%\n",
            "\n",
            "[Epoch 248/300]\n",
            "  Buffer size: 2490\n",
            "  Learning rate: 0.000082\n",
            "  Policy temperature: 0.0696\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 8.6\n",
            "  Avg successful length: 8.6\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5565\n",
            "  Alignment loss: 0.4658\n",
            "  Uniformity loss: 4.0908\n",
            "  Accuracy: 51.56%\n",
            "\n",
            "[Epoch 249/300]\n",
            "  Buffer size: 2500\n",
            "  Learning rate: 0.000079\n",
            "  Policy temperature: 0.0670\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 8.8\n",
            "  Avg successful length: 8.8\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5706\n",
            "  Alignment loss: 0.4709\n",
            "  Uniformity loss: 4.0997\n",
            "  Accuracy: 46.88%\n",
            "\n",
            "[Epoch 250/300]\n",
            "  Buffer size: 2510\n",
            "  Learning rate: 0.000076\n",
            "  Policy temperature: 0.0644\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 6.1\n",
            "  Avg successful length: 6.1\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6013\n",
            "  Alignment loss: 0.5104\n",
            "  Uniformity loss: 4.0909\n",
            "  Accuracy: 45.31%\n",
            "\n",
            "[Epoch 251/300]\n",
            "  Buffer size: 2520\n",
            "  Learning rate: 0.000074\n",
            "  Policy temperature: 0.0618\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 7.3\n",
            "  Avg successful length: 7.3\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5427\n",
            "  Alignment loss: 0.4598\n",
            "  Uniformity loss: 4.0829\n",
            "  Accuracy: 48.44%\n",
            "\n",
            "[Epoch 252/300]\n",
            "  Buffer size: 2530\n",
            "  Learning rate: 0.000071\n",
            "  Policy temperature: 0.0593\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 9.2\n",
            "  Avg successful length: 9.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5540\n",
            "  Alignment loss: 0.4461\n",
            "  Uniformity loss: 4.1079\n",
            "  Accuracy: 49.22%\n",
            "\n",
            "[Epoch 253/300]\n",
            "  Buffer size: 2540\n",
            "  Learning rate: 0.000069\n",
            "  Policy temperature: 0.0569\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 12.1\n",
            "  Avg successful length: 12.1\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5899\n",
            "  Alignment loss: 0.4952\n",
            "  Uniformity loss: 4.0947\n",
            "  Accuracy: 48.44%\n",
            "\n",
            "[Epoch 254/300]\n",
            "  Buffer size: 2550\n",
            "  Learning rate: 0.000066\n",
            "  Policy temperature: 0.0545\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 11.4\n",
            "  Avg successful length: 11.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6134\n",
            "  Alignment loss: 0.5069\n",
            "  Uniformity loss: 4.1065\n",
            "  Accuracy: 46.88%\n",
            "\n",
            "[Epoch 255/300]\n",
            "  Buffer size: 2560\n",
            "  Learning rate: 0.000064\n",
            "  Policy temperature: 0.0521\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 6.5\n",
            "  Avg successful length: 6.5\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5788\n",
            "  Alignment loss: 0.4697\n",
            "  Uniformity loss: 4.1091\n",
            "  Accuracy: 47.66%\n",
            "\n",
            "[Epoch 256/300]\n",
            "  Buffer size: 2570\n",
            "  Learning rate: 0.000062\n",
            "  Policy temperature: 0.0498\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 7.0\n",
            "  Avg successful length: 7.0\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5674\n",
            "  Alignment loss: 0.4797\n",
            "  Uniformity loss: 4.0877\n",
            "  Accuracy: 44.53%\n",
            "\n",
            "[Epoch 257/300]\n",
            "  Buffer size: 2580\n",
            "  Learning rate: 0.000059\n",
            "  Policy temperature: 0.0476\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 7.2\n",
            "  Avg successful length: 7.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5436\n",
            "  Alignment loss: 0.4514\n",
            "  Uniformity loss: 4.0922\n",
            "  Accuracy: 52.34%\n",
            "\n",
            "[Epoch 258/300]\n",
            "  Buffer size: 2590\n",
            "  Learning rate: 0.000057\n",
            "  Policy temperature: 0.0454\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 8.6\n",
            "  Avg successful length: 8.6\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5300\n",
            "  Alignment loss: 0.4327\n",
            "  Uniformity loss: 4.0973\n",
            "  Accuracy: 51.56%\n",
            "\n",
            "[Epoch 259/300]\n",
            "  Buffer size: 2600\n",
            "  Learning rate: 0.000055\n",
            "  Policy temperature: 0.0432\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 11.4\n",
            "  Avg successful length: 11.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6049\n",
            "  Alignment loss: 0.5147\n",
            "  Uniformity loss: 4.0902\n",
            "  Accuracy: 43.75%\n",
            "\n",
            "[Epoch 260/300]\n",
            "  Buffer size: 2610\n",
            "  Learning rate: 0.000053\n",
            "  Policy temperature: 0.0411\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 6.5\n",
            "  Avg successful length: 6.5\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5348\n",
            "  Alignment loss: 0.4381\n",
            "  Uniformity loss: 4.0967\n",
            "  Accuracy: 49.22%\n",
            "\n",
            "[Epoch 261/300]\n",
            "  Buffer size: 2620\n",
            "  Learning rate: 0.000051\n",
            "  Policy temperature: 0.0391\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 9.6\n",
            "  Avg successful length: 9.6\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5686\n",
            "  Alignment loss: 0.4740\n",
            "  Uniformity loss: 4.0946\n",
            "  Accuracy: 45.31%\n",
            "\n",
            "[Epoch 262/300]\n",
            "  Buffer size: 2630\n",
            "  Learning rate: 0.000049\n",
            "  Policy temperature: 0.0371\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 11.7\n",
            "  Avg successful length: 11.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5870\n",
            "  Alignment loss: 0.4917\n",
            "  Uniformity loss: 4.0953\n",
            "  Accuracy: 55.47%\n",
            "\n",
            "[Epoch 263/300]\n",
            "  Buffer size: 2640\n",
            "  Learning rate: 0.000047\n",
            "  Policy temperature: 0.0351\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 6.8\n",
            "  Avg successful length: 6.8\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5221\n",
            "  Alignment loss: 0.4248\n",
            "  Uniformity loss: 4.0973\n",
            "  Accuracy: 51.56%\n",
            "\n",
            "[Epoch 264/300]\n",
            "  Buffer size: 2650\n",
            "  Learning rate: 0.000045\n",
            "  Policy temperature: 0.0332\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 6.7\n",
            "  Avg successful length: 6.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5400\n",
            "  Alignment loss: 0.4331\n",
            "  Uniformity loss: 4.1069\n",
            "  Accuracy: 47.66%\n",
            "\n",
            "[Epoch 265/300]\n",
            "  Buffer size: 2660\n",
            "  Learning rate: 0.000043\n",
            "  Policy temperature: 0.0314\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 15.4\n",
            "  Avg successful length: 15.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6138\n",
            "  Alignment loss: 0.5125\n",
            "  Uniformity loss: 4.1013\n",
            "  Accuracy: 42.19%\n",
            "\n",
            "[Epoch 266/300]\n",
            "  Buffer size: 2670\n",
            "  Learning rate: 0.000041\n",
            "  Policy temperature: 0.0296\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 9.9\n",
            "  Avg successful length: 9.9\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6127\n",
            "  Alignment loss: 0.5111\n",
            "  Uniformity loss: 4.1016\n",
            "  Accuracy: 46.09%\n",
            "\n",
            "[Epoch 267/300]\n",
            "  Buffer size: 2680\n",
            "  Learning rate: 0.000039\n",
            "  Policy temperature: 0.0278\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 6.9\n",
            "  Avg successful length: 6.9\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5880\n",
            "  Alignment loss: 0.4936\n",
            "  Uniformity loss: 4.0944\n",
            "  Accuracy: 39.06%\n",
            "\n",
            "[Epoch 268/300]\n",
            "  Buffer size: 2690\n",
            "  Learning rate: 0.000038\n",
            "  Policy temperature: 0.0261\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 15.7\n",
            "  Avg successful length: 6.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6242\n",
            "  Alignment loss: 0.5291\n",
            "  Uniformity loss: 4.0952\n",
            "  Accuracy: 41.41%\n",
            "\n",
            "[Epoch 269/300]\n",
            "  Buffer size: 2700\n",
            "  Learning rate: 0.000036\n",
            "  Policy temperature: 0.0245\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 15.2\n",
            "  Avg successful length: 15.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5338\n",
            "  Alignment loss: 0.4397\n",
            "  Uniformity loss: 4.0941\n",
            "  Accuracy: 52.34%\n",
            "\n",
            "[Epoch 270/300]\n",
            "  Buffer size: 2710\n",
            "  Learning rate: 0.000034\n",
            "  Policy temperature: 0.0229\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 16.7\n",
            "  Avg successful length: 7.3\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5482\n",
            "  Alignment loss: 0.4565\n",
            "  Uniformity loss: 4.0917\n",
            "  Accuracy: 49.22%\n",
            "\n",
            "[Epoch 271/300]\n",
            "  Buffer size: 2720\n",
            "  Learning rate: 0.000033\n",
            "  Policy temperature: 0.0213\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 7.2\n",
            "  Avg successful length: 7.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5783\n",
            "  Alignment loss: 0.4760\n",
            "  Uniformity loss: 4.1023\n",
            "  Accuracy: 45.31%\n",
            "\n",
            "[Epoch 272/300]\n",
            "  Buffer size: 2730\n",
            "  Learning rate: 0.000031\n",
            "  Policy temperature: 0.0199\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 16.8\n",
            "  Avg successful length: 7.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6111\n",
            "  Alignment loss: 0.5163\n",
            "  Uniformity loss: 4.0948\n",
            "  Accuracy: 42.97%\n",
            "\n",
            "[Epoch 273/300]\n",
            "  Buffer size: 2740\n",
            "  Learning rate: 0.000030\n",
            "  Policy temperature: 0.0184\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 7.5\n",
            "  Avg successful length: 7.5\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5867\n",
            "  Alignment loss: 0.4899\n",
            "  Uniformity loss: 4.0969\n",
            "  Accuracy: 50.78%\n",
            "\n",
            "[Epoch 274/300]\n",
            "  Buffer size: 2750\n",
            "  Learning rate: 0.000028\n",
            "  Policy temperature: 0.0170\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 6.2\n",
            "  Avg successful length: 6.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6346\n",
            "  Alignment loss: 0.5203\n",
            "  Uniformity loss: 4.1143\n",
            "  Accuracy: 42.19%\n",
            "\n",
            "[Epoch 275/300]\n",
            "  Buffer size: 2760\n",
            "  Learning rate: 0.000027\n",
            "  Policy temperature: 0.0157\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 7.8\n",
            "  Avg successful length: 7.8\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5781\n",
            "  Alignment loss: 0.4794\n",
            "  Uniformity loss: 4.0986\n",
            "  Accuracy: 47.66%\n",
            "\n",
            "[Epoch 276/300]\n",
            "  Buffer size: 2770\n",
            "  Learning rate: 0.000026\n",
            "  Policy temperature: 0.0144\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 6.7\n",
            "  Avg successful length: 6.7\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5990\n",
            "  Alignment loss: 0.5035\n",
            "  Uniformity loss: 4.0954\n",
            "  Accuracy: 43.75%\n",
            "\n",
            "[Epoch 277/300]\n",
            "  Buffer size: 2780\n",
            "  Learning rate: 0.000024\n",
            "  Policy temperature: 0.0132\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 6.3\n",
            "  Avg successful length: 6.3\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5896\n",
            "  Alignment loss: 0.4858\n",
            "  Uniformity loss: 4.1038\n",
            "  Accuracy: 42.19%\n",
            "\n",
            "[Epoch 278/300]\n",
            "  Buffer size: 2790\n",
            "  Learning rate: 0.000023\n",
            "  Policy temperature: 0.0120\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 19.1\n",
            "  Avg successful length: 10.0\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.4879\n",
            "  Alignment loss: 0.3958\n",
            "  Uniformity loss: 4.0922\n",
            "  Accuracy: 53.12%\n",
            "\n",
            "[Epoch 279/300]\n",
            "  Buffer size: 2800\n",
            "  Learning rate: 0.000022\n",
            "  Policy temperature: 0.0109\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 5.5\n",
            "  Avg successful length: 5.5\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5865\n",
            "  Alignment loss: 0.4984\n",
            "  Uniformity loss: 4.0882\n",
            "  Accuracy: 47.66%\n",
            "\n",
            "[Epoch 280/300]\n",
            "  Buffer size: 2810\n",
            "  Learning rate: 0.000021\n",
            "  Policy temperature: 0.0099\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 17.2\n",
            "  Avg successful length: 7.9\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5564\n",
            "  Alignment loss: 0.4609\n",
            "  Uniformity loss: 4.0955\n",
            "  Accuracy: 48.44%\n",
            "\n",
            "[Epoch 281/300]\n",
            "  Buffer size: 2820\n",
            "  Learning rate: 0.000020\n",
            "  Policy temperature: 0.0089\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 9.3\n",
            "  Avg successful length: 9.3\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5275\n",
            "  Alignment loss: 0.4380\n",
            "  Uniformity loss: 4.0895\n",
            "  Accuracy: 49.22%\n",
            "\n",
            "[Epoch 282/300]\n",
            "  Buffer size: 2830\n",
            "  Learning rate: 0.000019\n",
            "  Policy temperature: 0.0079\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 16.6\n",
            "  Avg successful length: 7.2\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6036\n",
            "  Alignment loss: 0.5099\n",
            "  Uniformity loss: 4.0938\n",
            "  Accuracy: 45.31%\n",
            "\n",
            "[Epoch 283/300]\n",
            "  Buffer size: 2840\n",
            "  Learning rate: 0.000018\n",
            "  Policy temperature: 0.0070\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 13.3\n",
            "  Avg successful length: 13.3\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5436\n",
            "  Alignment loss: 0.4451\n",
            "  Uniformity loss: 4.0984\n",
            "  Accuracy: 48.44%\n",
            "\n",
            "[Epoch 284/300]\n",
            "  Buffer size: 2850\n",
            "  Learning rate: 0.000017\n",
            "  Policy temperature: 0.0062\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 5.5\n",
            "  Avg successful length: 5.5\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6061\n",
            "  Alignment loss: 0.5133\n",
            "  Uniformity loss: 4.0928\n",
            "  Accuracy: 44.53%\n",
            "\n",
            "[Epoch 285/300]\n",
            "  Buffer size: 2860\n",
            "  Learning rate: 0.000016\n",
            "  Policy temperature: 0.0054\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 15.8\n",
            "  Avg successful length: 6.3\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5793\n",
            "  Alignment loss: 0.4869\n",
            "  Uniformity loss: 4.0924\n",
            "  Accuracy: 43.75%\n",
            "\n",
            "[Epoch 286/300]\n",
            "  Buffer size: 2870\n",
            "  Learning rate: 0.000015\n",
            "  Policy temperature: 0.0046\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 14.4\n",
            "  Avg successful length: 4.8\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5783\n",
            "  Alignment loss: 0.4847\n",
            "  Uniformity loss: 4.0936\n",
            "  Accuracy: 44.53%\n",
            "\n",
            "[Epoch 287/300]\n",
            "  Buffer size: 2880\n",
            "  Learning rate: 0.000015\n",
            "  Policy temperature: 0.0039\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 16.2\n",
            "  Avg successful length: 6.8\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5999\n",
            "  Alignment loss: 0.5058\n",
            "  Uniformity loss: 4.0941\n",
            "  Accuracy: 42.97%\n",
            "\n",
            "[Epoch 288/300]\n",
            "  Buffer size: 2890\n",
            "  Learning rate: 0.000014\n",
            "  Policy temperature: 0.0033\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 5.5\n",
            "  Avg successful length: 5.5\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5808\n",
            "  Alignment loss: 0.4828\n",
            "  Uniformity loss: 4.0980\n",
            "  Accuracy: 41.41%\n",
            "\n",
            "[Epoch 289/300]\n",
            "  Buffer size: 2900\n",
            "  Learning rate: 0.000013\n",
            "  Policy temperature: 0.0027\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 6.6\n",
            "  Avg successful length: 6.6\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6073\n",
            "  Alignment loss: 0.5115\n",
            "  Uniformity loss: 4.0958\n",
            "  Accuracy: 42.97%\n",
            "\n",
            "[Epoch 290/300]\n",
            "  Buffer size: 2910\n",
            "  Learning rate: 0.000013\n",
            "  Policy temperature: 0.0022\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 70.00% (7/10)\n",
            "  Avg trajectory length: 35.9\n",
            "  Avg successful length: 8.0\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5840\n",
            "  Alignment loss: 0.4911\n",
            "  Uniformity loss: 4.0929\n",
            "  Accuracy: 47.66%\n",
            "\n",
            "[Epoch 291/300]\n",
            "  Buffer size: 2920\n",
            "  Learning rate: 0.000012\n",
            "  Policy temperature: 0.0018\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 15.0\n",
            "  Avg successful length: 5.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6083\n",
            "  Alignment loss: 0.5046\n",
            "  Uniformity loss: 4.1037\n",
            "  Accuracy: 39.84%\n",
            "\n",
            "[Epoch 292/300]\n",
            "  Buffer size: 2930\n",
            "  Learning rate: 0.000012\n",
            "  Policy temperature: 0.0013\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 80.00% (8/10)\n",
            "  Avg trajectory length: 24.5\n",
            "  Avg successful length: 5.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5926\n",
            "  Alignment loss: 0.5010\n",
            "  Uniformity loss: 4.0916\n",
            "  Accuracy: 43.75%\n",
            "\n",
            "[Epoch 293/300]\n",
            "  Buffer size: 2940\n",
            "  Learning rate: 0.000011\n",
            "  Policy temperature: 0.0010\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 100.00% (10/10)\n",
            "  Avg trajectory length: 9.0\n",
            "  Avg successful length: 9.0\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6067\n",
            "  Alignment loss: 0.5082\n",
            "  Uniformity loss: 4.0985\n",
            "  Accuracy: 46.88%\n",
            "\n",
            "[Epoch 294/300]\n",
            "  Buffer size: 2950\n",
            "  Learning rate: 0.000011\n",
            "  Policy temperature: 0.0007\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 80.00% (8/10)\n",
            "  Avg trajectory length: 25.0\n",
            "  Avg successful length: 6.0\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6568\n",
            "  Alignment loss: 0.5623\n",
            "  Uniformity loss: 4.0945\n",
            "  Accuracy: 42.19%\n",
            "\n",
            "[Epoch 295/300]\n",
            "  Buffer size: 2960\n",
            "  Learning rate: 0.000011\n",
            "  Policy temperature: 0.0004\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 15.0\n",
            "  Avg successful length: 5.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5476\n",
            "  Alignment loss: 0.4527\n",
            "  Uniformity loss: 4.0949\n",
            "  Accuracy: 52.34%\n",
            "\n",
            "[Epoch 296/300]\n",
            "  Buffer size: 2970\n",
            "  Learning rate: 0.000010\n",
            "  Policy temperature: 0.0002\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 17.3\n",
            "  Avg successful length: 8.0\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.5780\n",
            "  Alignment loss: 0.4926\n",
            "  Uniformity loss: 4.0854\n",
            "  Accuracy: 44.53%\n",
            "\n",
            "[Epoch 297/300]\n",
            "  Buffer size: 2980\n",
            "  Learning rate: 0.000010\n",
            "  Policy temperature: 0.0001\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 16.2\n",
            "  Avg successful length: 6.8\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6945\n",
            "  Alignment loss: 0.6025\n",
            "  Uniformity loss: 4.0921\n",
            "  Accuracy: 41.41%\n",
            "\n",
            "[Epoch 298/300]\n",
            "  Buffer size: 2990\n",
            "  Learning rate: 0.000010\n",
            "  Policy temperature: 0.0000\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 17.7\n",
            "  Avg successful length: 8.4\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6051\n",
            "  Alignment loss: 0.4878\n",
            "  Uniformity loss: 4.1173\n",
            "  Accuracy: 42.97%\n",
            "\n",
            "[Epoch 299/300]\n",
            "  Buffer size: 3000\n",
            "  Learning rate: 0.000010\n",
            "  Policy temperature: 0.0000\n",
            "  --- Policy Performance ---\n",
            "  Success rate: 90.00% (9/10)\n",
            "  Avg trajectory length: 14.9\n",
            "  Avg successful length: 5.3\n",
            "  --- Training Metrics ---\n",
            "  Total loss: 4.6163\n",
            "  Alignment loss: 0.5111\n",
            "  Uniformity loss: 4.1053\n",
            "  Accuracy: 43.75%\n",
            "\n",
            "Training complete!\n",
            "\n",
            "✓ Training complete!\n"
          ]
        }
      ],
      "source": [
        "# Create and train heuristic\n",
        "heuristic = DistanceHeuristicV4(config=heuristic_config, \n",
        "                                env=system.env,\n",
        "                                perceiver=system.perceiver,\n",
        "                                atoms_to_node=atoms_to_node,\n",
        "                                node_to_states=training_data.node_states,\n",
        "                                seed=42)\n",
        "\n",
        "print(\"\\nStarting training...\\n\")\n",
        "heuristic.train(\n",
        "    state_node_pairs=state_node_pairs,\n",
        "    num_epochs=300,\n",
        "    trajectories_per_epoch=10,\n",
        "    max_episode_steps=100\n",
        ")\n",
        "\n",
        "print(\"\\n✓ Training complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Node transitions:\n",
            "  0 → 0: 17338\n",
            "  0 → 1: 680\n",
            "  0 → 2: 781\n",
            "  1 → 0: 772\n",
            "  1 → 1: 15388\n",
            "  1 → 3: 751\n",
            "  2 → 0: 806\n",
            "  2 → 2: 18953\n",
            "  2 → 3: 823\n",
            "  3 → 1: 821\n",
            "  3 → 2: 818\n",
            "  3 → 3: 17705\n"
          ]
        }
      ],
      "source": [
        "# Count node transitions in replay buffer\n",
        "from collections import Counter\n",
        "transitions = Counter()\n",
        "\n",
        "for traj in heuristic.replay_buffer.trajectories:\n",
        "    nodes = traj['nodes']\n",
        "    for i in range(len(nodes) - 1):\n",
        "        transitions[(nodes[i], nodes[i+1])] += 1\n",
        "\n",
        "print(\"Node transitions:\")\n",
        "for (n0, n1), count in sorted(transitions.items()):\n",
        "    print(f\"  {n0} → {n1}: {count}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Inspect Trajectories\n",
        "\n",
        "Check if the policy is successfully reaching goal nodes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Last trajectory:\n",
            "  States: [array([0., 1.], dtype=float32), array([0., 2.], dtype=float32), array([0., 3.], dtype=float32), array([0., 4.], dtype=float32), array([0., 5.], dtype=float32)]\n",
            "  Nodes: [2, 2, 2, 2, 3]\n",
            "\n",
            "Metadata:\n",
            "  Start state: [0. 1.]\n",
            "  Goal node: 3\n",
            "\n",
            "Did it reach goal? True\n"
          ]
        }
      ],
      "source": [
        "# Look at last trajectory\n",
        "ind = 5\n",
        "last_trajectory = heuristic.replay_buffer.trajectories[-ind]\n",
        "last_metadata = heuristic.replay_buffer.trajectory_metadata[-ind]\n",
        "\n",
        "print(\"Last trajectory:\")\n",
        "print(f\"  States: {([x for x in last_trajectory['states']])}\")\n",
        "print(f\"  Nodes: {last_trajectory['nodes']}\")\n",
        "print(f\"\\nMetadata:\")\n",
        "print(f\"  Start state: {last_metadata['start_state']}\")\n",
        "print(f\"  Goal node: {last_metadata['goal_node']}\")\n",
        "print(f\"\\nDid it reach goal? {last_trajectory['nodes'][-1] == last_metadata['goal_node']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing rollout:\n",
            "  Start state (flattened): [5. 0.]\n",
            "  Goal node: 3\n",
            "\n",
            "Created start state: [[5. 0.]]\n",
            "[array([5., 0.], dtype=float32), array([4., 0.], dtype=float32), array([3., 0.], dtype=float32), array([2., 0.], dtype=float32), array([1., 0.], dtype=float32), array([1., 1.], dtype=float32), array([1., 2.], dtype=float32), array([1., 3.], dtype=float32), array([1., 4.], dtype=float32), array([1., 5.], dtype=float32)]\n",
            "True\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "# Test rollout on a specific state-node pair\n",
        "import numpy as np\n",
        "from tamp_improv.benchmarks.gridworld import GraphInstance\n",
        "\n",
        "# Reconstruct the start state from the metadata\n",
        "# The metadata shows: [0. 0. 5. 0. 1. 0. 1. 7. 9. 1. 1. 1.]\n",
        "# This appears to be the full GraphInstance.nodes flattened\n",
        "# For gridworld with 2 objects, nodes shape is (2, 6)\n",
        "start_node = 0\n",
        "start_state = training_data.node_states[start_node][0]\n",
        "start_state_flat = heuristic._flatten_state(start_state)\n",
        "goal_node = 3\n",
        "\n",
        "print(\"Testing rollout:\")\n",
        "print(f\"  Start state (flattened): {start_state_flat}\")\n",
        "print(f\"  Goal node: {goal_node}\")\n",
        "\n",
        "print(f\"\\nCreated start state: {start_state.nodes}\")\n",
        "\n",
        "states, nodes, success = heuristic.rollout(\n",
        "    system.env,\n",
        "    start_state,\n",
        "    goal_node,\n",
        "    max_steps=150,\n",
        ")\n",
        "\n",
        "print([x for x in states])\n",
        "print(success)\n",
        "print(len(states))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Closest states to each node:\n",
            "  Node 0: Closest to state [9. 1.] (distance: 0.066)\n",
            "  Node 1: Closest to state [9. 9.] (distance: 0.038)\n",
            "  Node 2: Closest to state [0. 0.] (distance: 0.004)\n",
            "  Node 3: Closest to state [2. 9.] (distance: 0.002)\n"
          ]
        }
      ],
      "source": [
        "# Visualize 2D embeddings for states and nodes\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Generate all possible gridworld positions\n",
        "# For a 2-cell gridworld with 5 states per cell: 10x10 grid\n",
        "grid_size = 10\n",
        "state_positions = []\n",
        "state_embeddings = []\n",
        "\n",
        "# Encode all grid positions\n",
        "for s, _ in state_node_pairs:   \n",
        "    # Get normalized state embedding\n",
        "    state = heuristic._flatten_state(s)\n",
        "    state_positions.append(state)\n",
        "    with torch.no_grad():\n",
        "        state_tensor = torch.FloatTensor(state).unsqueeze(0).to(heuristic.device)\n",
        "        emb = heuristic.s_encoder(state_tensor).squeeze(0)\n",
        "        emb_normalized = F.normalize(emb.unsqueeze(0), p=2, dim=1).squeeze(0)\n",
        "        state_embeddings.append(emb_normalized.cpu().numpy())\n",
        "\n",
        "state_embeddings = np.array(state_embeddings)\n",
        "\n",
        "# Get normalized node embeddings\n",
        "with torch.no_grad():\n",
        "    node_embeddings_raw = heuristic.g_encoder.cpu()\n",
        "    node_embeddings_normalized = F.normalize(node_embeddings_raw, p=2, dim=1).numpy()\n",
        "\n",
        "# Create visualization\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Left plot: State embeddings colored by position\n",
        "plt.subplot(1, 2, 1)\n",
        "scatter = plt.scatter(state_embeddings[:, 0], state_embeddings[:, 1], \n",
        "                     c=[x for x, y in state_positions], cmap='viridis', \n",
        "                     alpha=0.6, s=30)\n",
        "plt.colorbar(scatter, label='X position')\n",
        "plt.xlabel('Embedding Dimension 1')\n",
        "plt.ylabel('Embedding Dimension 2')\n",
        "plt.title('State Embeddings (s_encoder)\\nColored by X position')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.axis('equal')\n",
        "\n",
        "# Right plot: Node embeddings + representative states\n",
        "plt.subplot(1, 2, 2)\n",
        "\n",
        "# Plot all state embeddings lightly in background\n",
        "plt.scatter(state_embeddings[:, 0], state_embeddings[:, 1], \n",
        "           c='lightgray', alpha=0.3, s=20, label='All states')\n",
        "\n",
        "# Plot node embeddings as large markers\n",
        "node_labels = ['Node 0\\n(0,0)', 'Node 1\\n(0,1)', 'Node 2\\n(1,0)', \n",
        "               'Node 3\\n(1,1)', 'Node 4\\n(1,1)+Goal']\n",
        "colors = ['red', 'blue', 'green', 'orange', 'purple']\n",
        "\n",
        "for i, (emb, label, color) in enumerate(zip(node_embeddings_normalized, node_labels, colors)):\n",
        "    plt.scatter(emb[0], emb[1], s=200, marker='*', \n",
        "               color=color, edgecolors='black', linewidths=2,\n",
        "               label=label, zorder=10)\n",
        "    \n",
        "    # Add text annotation\n",
        "    plt.annotate(f'N{i}', (emb[0], emb[1]), \n",
        "                fontsize=10, fontweight='bold',\n",
        "                ha='center', va='center')\n",
        "\n",
        "plt.xlabel('Embedding Dimension 1')\n",
        "plt.ylabel('Embedding Dimension 2')\n",
        "plt.title('Node Embeddings (g_encoder) vs State Embeddings')\n",
        "plt.legend(loc='best', fontsize=8)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.axis('equal')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print which states are closest to each node\n",
        "print(\"\\nClosest states to each node:\")\n",
        "for node_id in range(len(node_embeddings_normalized)):\n",
        "    node_emb = node_embeddings_normalized[node_id]\n",
        "    \n",
        "    # Compute distances from this node to all states\n",
        "    distances = np.linalg.norm(state_embeddings - node_emb, axis=1)\n",
        "    closest_idx = np.argmin(distances)\n",
        "    closest_pos = state_positions[closest_idx]\n",
        "    \n",
        "    print(f\"  Node {node_id}: Closest to state {closest_pos} (distance: {distances[closest_idx]:.3f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 6: Evaluate Distance Heuristic\n",
        "\n",
        "Compare learned distances with true distances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Evaluating learned distances...\n",
            "[GraphInstance(nodes=array([[1., 1.]], dtype=float32), edges=None, edge_links=None), GraphInstance(nodes=array([[4., 4.]], dtype=float32), edges=None, edge_links=None), GraphInstance(nodes=array([[1., 3.]], dtype=float32), edges=None, edge_links=None), GraphInstance(nodes=array([[4., 3.]], dtype=float32), edges=None, edge_links=None), GraphInstance(nodes=array([[0., 4.]], dtype=float32), edges=None, edge_links=None), GraphInstance(nodes=array([[2., 3.]], dtype=float32), edges=None, edge_links=None), GraphInstance(nodes=array([[3., 4.]], dtype=float32), edges=None, edge_links=None), GraphInstance(nodes=array([[0., 0.]], dtype=float32), edges=None, edge_links=None), GraphInstance(nodes=array([[4., 0.]], dtype=float32), edges=None, edge_links=None), GraphInstance(nodes=array([[0., 3.]], dtype=float32), edges=None, edge_links=None), GraphInstance(nodes=array([[1., 4.]], dtype=float32), edges=None, edge_links=None), GraphInstance(nodes=array([[1., 2.]], dtype=float32), edges=None, edge_links=None), GraphInstance(nodes=array([[2., 4.]], dtype=float32), edges=None, edge_links=None), GraphInstance(nodes=array([[0., 1.]], dtype=float32), edges=None, edge_links=None), GraphInstance(nodes=array([[4., 2.]], dtype=float32), edges=None, edge_links=None), GraphInstance(nodes=array([[1., 0.]], dtype=float32), edges=None, edge_links=None), GraphInstance(nodes=array([[4., 1.]], dtype=float32), edges=None, edge_links=None), GraphInstance(nodes=array([[3., 1.]], dtype=float32), edges=None, edge_links=None), GraphInstance(nodes=array([[2., 0.]], dtype=float32), edges=None, edge_links=None)]\n"
          ]
        },
        {
          "ename": "NotImplementedError",
          "evalue": "True distance computation not implemented for GridworldFixedTAMPSystem",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Get true distance (from rollouts)\u001b[39;00m\n\u001b[32m     16\u001b[39m target_atoms = planning_graph.nodes[target_node].atoms\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m true_dist = \u001b[43mcompute_true_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_atoms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m results.append({\n\u001b[32m     20\u001b[39m     \u001b[33m'\u001b[39m\u001b[33msource_idx\u001b[39m\u001b[33m'\u001b[39m: i,\n\u001b[32m     21\u001b[39m     \u001b[33m'\u001b[39m\u001b[33msource_node\u001b[39m\u001b[33m'\u001b[39m: source_node,\n\u001b[32m   (...)\u001b[39m\u001b[32m     24\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mtarget_node\u001b[39m\u001b[33m'\u001b[39m: target_node,\n\u001b[32m     25\u001b[39m })\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (i + \u001b[32m1\u001b[39m) % \u001b[32m20\u001b[39m == \u001b[32m0\u001b[39m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/thesis/tamp_physical_improvisation/src/tamp_improv/approaches/improvisational/analyze.py:356\u001b[39m, in \u001b[36mcompute_true_distance\u001b[39m\u001b[34m(system, start_state, goal_node_atoms)\u001b[39m\n\u001b[32m    354\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m compute_true_distance_gridworld(system, start_state, goal_node_atoms)\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m356\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m    357\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTrue distance computation not implemented for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(system).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    358\u001b[39m     )\n",
            "\u001b[31mNotImplementedError\u001b[39m: True distance computation not implemented for GridworldFixedTAMPSystem"
          ]
        }
      ],
      "source": [
        "from tamp_improv.approaches.improvisational.analyze import compute_true_distance\n",
        "import random\n",
        "\n",
        "print(\"\\nEvaluating learned distances...\")\n",
        "results = []\n",
        "\n",
        "sampled_pairs = [random.choice(state_node_pairs) for _ in range(100)]\n",
        "for i, (source_state, target_node) in enumerate(sampled_pairs):\n",
        "    # Get learned distance\n",
        "    source_node = heuristic.get_node(source_state)\n",
        "    if source_node == 4 or target_node == 4:\n",
        "        continue\n",
        "    learned_dist = heuristic.estimate_distance(source_state, target_node)\n",
        "    \n",
        "    # Get true distance (from rollouts)\n",
        "    target_atoms = planning_graph.nodes[target_node].atoms\n",
        "    true_dist = compute_true_distance(system, source_state, target_atoms)\n",
        "    \n",
        "    results.append({\n",
        "        'source_idx': i,\n",
        "        'source_node': source_node,\n",
        "        'learned_distance': learned_dist,\n",
        "        'true_distance': true_dist,\n",
        "        'target_node': target_node,\n",
        "    })\n",
        "    \n",
        "    if (i + 1) % 20 == 0:\n",
        "        print(f\"  Evaluated {i + 1}/{len(sampled_pairs)} pairs...\")\n",
        "\n",
        "print(f\"\\n✓ Evaluated {len(results)} state-node pairs\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 7: Analyze Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Results Summary:\n",
            "  Total pairs: 69\n",
            "  Finite distance pairs: 37\n",
            "\n",
            "Statistics:\n",
            "  MAE: 2.79\n",
            "  RMSE: 3.69\n",
            "  Correlation: 0.573\n",
            "\n",
            "Distance Ranges:\n",
            "  True:    [1.0, 10.0]\n",
            "  Learned: [-0.5, 13.6]\n"
          ]
        }
      ],
      "source": [
        "# Filter finite results\n",
        "finite_results = [r for r in results if r['true_distance'] != float('inf') and r['true_distance'] > 0]\n",
        "\n",
        "print(f\"\\nResults Summary:\")\n",
        "print(f\"  Total pairs: {len(results)}\")\n",
        "print(f\"  Finite distance pairs: {len(finite_results)}\")\n",
        "\n",
        "if finite_results:\n",
        "    true_dists = np.array([r['true_distance'] for r in finite_results])\n",
        "    learned_dists = np.array([r['learned_distance'] for r in finite_results])\n",
        "    \n",
        "    # Statistics\n",
        "    mae = np.mean(np.abs(true_dists - learned_dists))\n",
        "    rmse = np.sqrt(np.mean((true_dists - learned_dists) ** 2))\n",
        "    correlation = np.corrcoef(true_dists, learned_dists)[0, 1]\n",
        "    \n",
        "    print(f\"\\nStatistics:\")\n",
        "    print(f\"  MAE: {mae:.2f}\")\n",
        "    print(f\"  RMSE: {rmse:.2f}\")\n",
        "    print(f\"  Correlation: {correlation:.3f}\")\n",
        "    \n",
        "    print(f\"\\nDistance Ranges:\")\n",
        "    print(f\"  True:    [{true_dists.min():.1f}, {true_dists.max():.1f}]\")\n",
        "    print(f\"  Learned: [{learned_dists.min():.1f}, {learned_dists.max():.1f}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sample Comparisons (sorted by true distance):\n",
            " Idx | Source Node | Target Node |   True |  Learned |  Error\n",
            "---------------------------------------------\n",
            "  52 |    1 |    2 |    1.0 |      3.0 |    2.0\n",
            "  63 |    1 |    3 |    1.0 |     -0.5 |    1.5\n",
            "  93 |    1 |    3 |    1.0 |     -0.5 |    1.5\n",
            "   6 |    2 |    3 |    2.0 |      4.5 |    2.5\n",
            "   9 |    2 |    1 |    2.0 |      7.0 |    5.0\n",
            "  31 |    1 |    2 |    2.0 |      4.6 |    2.6\n",
            "  34 |    2 |    1 |    2.0 |      7.0 |    5.0\n",
            "  35 |    1 |    3 |    2.0 |      0.1 |    1.9\n",
            "  48 |    2 |    1 |    2.0 |      7.0 |    5.0\n",
            "  51 |    2 |    3 |    2.0 |      4.5 |    2.5\n",
            "  96 |    2 |    3 |    2.0 |      4.5 |    2.5\n",
            "  15 |    0 |    1 |    3.0 |      6.4 |    3.4\n",
            "  18 |    1 |    3 |    3.0 |      3.2 |    0.2\n",
            "  19 |    0 |    2 |    3.0 |      2.5 |    0.5\n",
            "  30 |    1 |    3 |    3.0 |      3.2 |    0.2\n",
            "  38 |    1 |    2 |    3.0 |      7.1 |    4.1\n",
            "  39 |    0 |    2 |    3.0 |      2.5 |    0.5\n",
            "  50 |    0 |    1 |    3.0 |      6.4 |    3.4\n",
            "  53 |    1 |    3 |    3.0 |      3.2 |    0.2\n",
            "  61 |    0 |    2 |    3.0 |      2.5 |    0.5\n",
            "  70 |    1 |    3 |    3.0 |      3.2 |    0.2\n",
            "  72 |    1 |    3 |    3.0 |      3.2 |    0.2\n",
            "  76 |    2 |    3 |    4.0 |      7.7 |    3.7\n",
            "  16 |    2 |    1 |    5.0 |     11.8 |    6.8\n",
            "  23 |    0 |    2 |    5.0 |      5.8 |    0.8\n",
            "  26 |    2 |    1 |    5.0 |     11.8 |    6.8\n",
            "  32 |    0 |    1 |    5.0 |      8.0 |    3.0\n",
            "  44 |    1 |    2 |    5.0 |     13.6 |    8.6\n",
            "  47 |    0 |    1 |    5.0 |      4.1 |    0.9\n",
            "  49 |    0 |    2 |    5.0 |      6.1 |    1.1\n",
            "  68 |    1 |    2 |    5.0 |     13.6 |    8.6\n",
            "  73 |    2 |    1 |    5.0 |     11.8 |    6.8\n",
            "  75 |    0 |    3 |    5.0 |      6.3 |    1.3\n",
            "  79 |    2 |    3 |    5.0 |     10.3 |    5.3\n",
            "  83 |    0 |    1 |    5.0 |      4.1 |    0.9\n",
            "  57 |    0 |    3 |   10.0 |      8.7 |    1.3\n",
            "  94 |    0 |    3 |   10.0 |      8.7 |    1.3\n"
          ]
        }
      ],
      "source": [
        "# Show sample comparisons\n",
        "if finite_results:\n",
        "    print(\"\\nSample Comparisons (sorted by true distance):\")\n",
        "    print(f\"{'Idx':>4} | {'Source Node':>4} | {'Target Node':>4} | {'True':>6} | {'Learned':>8} | {'Error':>6}\")\n",
        "    print(\"-\" * 45)\n",
        "    \n",
        "    # sorted_results = finite_results\n",
        "    sorted_results = sorted(finite_results, key=lambda r: r['true_distance'])\n",
        "    for r in sorted_results:  # Show first 20\n",
        "        error = abs(r['true_distance'] - r['learned_distance'])\n",
        "        print(\n",
        "            f\"{r['source_idx']:>4} | \"\n",
        "            f\"{r['source_node']:>4} | \"\n",
        "            f\"{r['target_node']:>4} | \"\n",
        "            f\"{r['true_distance']:>6.1f} | \"\n",
        "            f\"{r['learned_distance']:>8.1f} | \"\n",
        "            f\"{error:>6.1f}\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 8: Visualize Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "if finite_results:\n",
        "    true_dists = np.array([r['true_distance'] for r in finite_results])\n",
        "    learned_dists = np.array([r['learned_distance'] for r in finite_results])\n",
        "    \n",
        "    plt.figure(figsize=(10, 5))\n",
        "    \n",
        "    # Scatter plot\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.scatter(true_dists, learned_dists, alpha=0.6)\n",
        "    plt.plot([true_dists.min(), true_dists.max()], \n",
        "             [true_dists.min(), true_dists.max()], \n",
        "             'r--', label='Perfect correlation')\n",
        "    plt.xlabel('True Distance')\n",
        "    plt.ylabel('Learned Distance')\n",
        "    plt.title(f'Learned vs True Distance\\n(Correlation: {correlation:.3f})')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Error distribution\n",
        "    plt.subplot(1, 2, 2)\n",
        "    errors = true_dists - learned_dists\n",
        "    plt.hist(errors, bins=20, alpha=0.7, edgecolor='black')\n",
        "    plt.xlabel('Error (True - Learned)')\n",
        "    plt.ylabel('Count')\n",
        "    plt.title(f'Error Distribution\\n(MAE: {mae:.2f}, RMSE: {rmse:.2f})')\n",
        "    plt.axvline(0, color='r', linestyle='--', label='Zero error')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No results to visualize!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 9: Check Embedding Quality\n",
        "\n",
        "Inspect if node embeddings are well-separated."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get all node embeddings\n",
        "with torch.no_grad():\n",
        "    node_embeddings = heuristic.g_encoder.cpu().numpy()\n",
        "\n",
        "print(\"Node embeddings:\")\n",
        "for i, emb in enumerate(node_embeddings):\n",
        "    print(f\"  Node {i}: {emb}\")\n",
        "\n",
        "# Compute pairwise distances\n",
        "from scipy.spatial.distance import pdist, squareform\n",
        "pairwise_dists = squareform(pdist(node_embeddings))\n",
        "\n",
        "print(\"\\nPairwise distances between node embeddings:\")\n",
        "print(pairwise_dists)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 10: Save Heuristic (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save trained heuristic\n",
        "save_path = Path.cwd() / \"outputs\" / \"distance_heuristic_v4\"\n",
        "save_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "heuristic.save(str(save_path / \"model\"))\n",
        "print(f\"\\n✓ Saved heuristic to {save_path}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "slap_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
