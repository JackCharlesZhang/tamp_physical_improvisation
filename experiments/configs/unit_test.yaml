seed: 42
debug: true
render_mode: null

env:
  name: GridworldFixedTAMPSystem
  # Gridworld
  num_cells: 3
  num_states_per_cell: 10
  num_teleporters: 0

  # Blocks
  n_blocks: 2
  num_obstacle_blocks: 3


collection:
  num_episodes: 5
  max_steps_per_edge: 100
  planner_id: pyperplan

heuristic:
  # Heuristic Parameters
  type: rollouts

  # Rollout Heuristic Parameters
  use_random_rollouts: true
  num_rollouts_per_node: 100
  max_steps_per_rollout: 100
  shortcut_success_threshold: 0.1
  action_scale: 1.0

  # CRL Heuristic Parameters

  hidden_dims: [64, 64]
  latent_dim: 16
  normalize_embeddings: true
  learning_rate: 1e-3
  batch_size: 256
  buffer_size: 100000
  gamma: 0.99
  repetition_factor: 2
  policy_temperature: 1.0
  iters_per_epoch: 1
  learn_frequency: 1

  n_epochs: 1  # Epochs per round (used as num_epochs_per_round in multi_train)
  trajectories_per_epoch: 10
  max_episode_steps: 100

  num_rounds: 1  # Number of pruning rounds (1 = no pruning, just normal train)
  keep_fraction: 0.5  # Fraction of node-node pairs to keep each round

  eval_rollouts: 1
  eval_temperature: 0
  eval_max_steps: 10

  max_shortcuts_per_graph: 1

policy:
  type: multiRL
  learning_rate: 3.0e-4
  batch_size: 32
  n_epochs: 1
  gamma: 0.99
  ent_coef: 0.01
  deterministic: false
  early_stopping: true
  max_episode_steps: 100
  episodes_per_scenario: 1
  training_record_interval: 10

  eval_rollouts: 10


evaluation:
  render: false
  fast_eval: false
  num_episodes: 3
  max_episode_steps: 100



