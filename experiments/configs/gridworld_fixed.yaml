env_name: GridworldFixedTAMPSystem
render_mode: null

num_cells: 3
num_states_per_cell: 10
num_teleporters: 0

seed: 42
debug: false

# num_episodes: 50
# max_steps: 50
# max_training_steps_per_shortcut: 50


force_collect: false
force_train_policy: false
force_train_heuristic: false
force_prune: false

render: false
training_record_interval: 10

# Pipeline cache directory (can be overridden via command line)
# Example: pipeline_cache_dir=/scratch/.../pipeline_cache/obstacle2d
pipeline_cache_dir: null

# Collection parameters
collect_episodes: 100


# Distance heuristic V4 parameters
hidden_dims: [64, 64]
latent_dim: 16
learning_rate: 1e-3
batch_size: 256
buffer_size: 100000
gamma: 0.99
repetition_factor: 2
policy_temperature: 1.0
iters_per_epoch: 100
learn_frequency: 1

# Training parameters for V4
num_epochs: 1
trajectories_per_epoch: 10
max_episode_steps: 100

# Evaluation parameters for V4
eval_rollouts: 3
eval_temperature: 0
eval_max_steps: 100


# SLAP Pipeline Configs
# Pruning method: "none", "rollouts", or "distance_heuristic"
pruning_method: random

max_training_steps_per_shortcut: 100
episodes_per_scenario: 300


use_random_rollouts: true
num_rollouts_per_node: 1000
max_steps_per_rollout: 100
shortcut_success_threshold: 1
max_shortcuts_per_graph: 0

deterministic: false
early_stopping: true
fast_eval: false

# Legacy SLAP Configs
rl_learning_rate: 3.0e-4
rl_batch_size: 32
rl_n_epochs: 10
rl_gamma: 0.99
rl_ent_coef: 0.01
